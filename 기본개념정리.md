# 프로젝트를 진행하면서 사용한 기술스택들에대한 기본 개념정리

많지는않지만 프로젝트들을 진행하면서 여러 기술들을 사용하게되었다.
보통 프로젝트에 기술을 적용하면서 바로바로 기본개념들을 간단하게 정리해놨지만 기술들의 갯수가 많아지고 프로젝트에 적용시키면서 트러블슈팅들을 같이 작성해놓으니까 찾아보기가 힘들어지는 문제점이생겼다.

그래서 프로젝트에 이용했던 기술 스택들에대한 기본 개념들을 이곳에 정리해놓고 필요할때 찾아보는편이 낫겠다고 판단하여 작성.

- Celery
- Redis
- Airflow
- Django
- GCP
- Kafka
- Hadoop & hdfs
- Spark
- Elastic search
- logstash
- Kibana 
- SQL
- Nginx
- uWsgi
- Zookeeper
- Pandas
- Numpy
- Docker
- CloudFlare
## Celery와 사용이유

Celery는 많은 작업을 분산처리를 할 수있도록 해주는 Task queue이다. <u>Task는 비동기 처리를 도와주는 친구로 Celery는 비동기 작업 큐 라고 생각하면된다.</u>

<u>그럼 비동기 작업이 왜 필요한가?</u> 

이건 간단하게 생각하면 쉽다.
예를 들어 내가 스타벅스의 매장을 조회하기위하여 스타벅스 홈페이지에 접속하여 매장 조회를 눌렀다고 가정하자.

그런데 웹 페이지의 경우, 전국의 스타벅스 매장의 정보를 DB에서 가져오기때문에 이 가져오는 작업이 끝날때까지 나는 하염없이 웹 페이지의 응답을 기다려야한다.

그래서 그러한 무거운 연산 및 처리들을 Task라는 비동기 작업을 처리해주는 큐에 넘겨주고, 이용자는 다른작업을 할 수 있도록하는것이 원리이다.
그런고로 Celery는 클라이언트와 worker사이를 중재하는 메세지 브로커를 사용하여 통신하게되는데, worker들에게 task를 처리하도록 시키기위해 메세지 브로커로써 Redis나 Rabbit MQ를 사용하게된다.


그럼 queue는 뭘까? 이건 컨테이너벨트에 적재된 화물을 생각하면 쉽다.
예를들어, 택배사에서 컨테이너 벨트위에 배송되야할 택배들이 줄지어있다고치면 이 화물들이 처리해야할 작업이되는것이고 큐는 컨테이너벨트가되는것이다.

그러면 컨테이너벨트에 택배(화물)을 올려주는 작업을해주는 친구가 필요한데, 그 역할을하는게 시스템 브로커이다.

클라이언트에서 처리해야할 작업(task)를 생성하면 celery는 브로커를 통해 worker들에게 메세지를 전달하여 worker들이 해당 작업을 처리하게한다.

celery는 1분에 수백만건의 task를 처리할수있는 속도를 제공하기때문에 분산작업 처리를할때 유용하다.

보통 Airflow+celery+redis or rabbit mq를 많이 사용한다.

## Redis

<u>Airflow와 Redis</u>

redis를 airflow와 함께 사용할때는 보통 메세지 브로커로써 활용한다.
하지만 Redis의 태생 자체가 메세지 브로커가아니라 인 메모리 db로, <u>Key-value형식을가진 Nosql에 속하는 자료구조 서버이다</u>

우리가 흔히 사용하는 DB는 데이터를 물리 디스크에 직접써서 요청,쿼리가 발생할때마다 디스크에 접근하여 데이터를가져온다.
이러한 방법은 <u>서버에 장애가 발생하여도 데이터가 손실되지않는다.</u>

하지만 단점이있다.
사용자가 늘어가서 데이터베이스에 요청되는 쿼리가 커지고 많아진다면 디스크에 접근하는 횟수도 많아지기때문에 DB에 부하가발생하고 속도가 현저히 느려진다.

이때 캐시(메모리 기반) 서버를 도입하게되는데 이 Redis라는것이 인 메모리 DB이다.

캐시서버의 특징은 한번읽어온 데이터를 임의의 공간에 저장하여 다음에 읽을때 새로 읽어오는게 아니라 저장하고있던 정보를 빠르게 받아볼수있게 도와준다.

캐시서버가 한번 읽어온 데이터를 임의의 공간에 저장하고있기때문에, 당연히 매번 데이터베이스를 거치지않기때문에 DB의 부하를 줄이고 서비스 속도도 느려지지않는 장점이있다.

Airflow에서 redis를 같이쓰게되면 redis가 메세지 브로커로써 클라이언트가 생성한 Task가 지정된 큐에따라 redis서버안에 Key-Value타입으로 쌓이는것을 확인할수있다.

만약 내가 airflow task에 큐를 worker-1이라고 지정해놓으면 celery worker를 실행시킬때 워커가 모니터링할 큐를 worker-1이라고 지정해놓으면 해당 worker가 redis 큐 안의 task를 순차적으로 처리하게된다. 

redis 큐 안에 적재되는 task는 <u>task id</u>라는 고유한 task 아이디값이 있어서 아이디 값에따라 순차적으로 처리되는것을 확인할수있었다.

그렇다면 기본 Redis에 대해서 조금 더 알아보자.

Redis의 Key값의 자료형은 String형이지만 Value값의 자료형은 다양한 타입을 지원한다.

서버가 1개라면 굳이 Redis를 사용할필요는없겠지만(인 메모리 데이터베이스로써), 분산환경에서라면 원격 프로세스간의 데이터를 일치시키기가 Redis가 더욱 편리하다.

Redis의 단점은 무엇일까?

1.메모리 기반 DB이기때문에 서버에 장애가 발생했을시 데이터의 유실이있다.

2.메모리 기반 DB이기떄문에 메모리관리가중요하다.

3.싱글 스레드의 특성상, 처리하는데 시간이 오래걸리는 요청이나 명령은 비효율적이다.

### Redis VS Rabbit MQ

둘다 Airflow에서 메세지 브로커로 주로 활용된다.

두가지 다 Airflow와 사용하기 좋지만, 조금씩 특징이 다르다.

<u>Redis</u>

Key-Value를 이용해 Celery가 처리할 작업을 Celery에 보낸 후 캐시에서 해당 Key를 제거하는 방식으로 작동한다.

1.Redis는 데이터 검색을 위해 Database에 접근하기 전 메모리에서 Cache를 가져다 쓴다는 점에서 속도가 빠르다.

2.매우 빠른 서비스 및 메모리 내 기능을 제공하기 때문에 지속성이 중요하지 않고 약간의 손실을 견딜 수있는 짧은 보존 메시지에 적합하다.

3.큰 메시지를 처리 할 때는 대기 시간이 오래 걸린다.


<u> Rabbit MQ</u>

응용 프로그램(applications)에게 메시지를 주고 받을 수 있으며, 메시지가 수신될 때까지 안전하게 있을 수 있도록 하는 공용 플래폼(common platform)을 제공한다.

1.메시지를 다른 대기열로 보낼 수있는 라우팅 시스템을 갖추고 있다.

2.우선 순위가 높은 메시지를 먼저 사용하기 위해 작업자가 사용할 수있는 메시지의 우선 순위를 지원한다.

3.메시지 브로커로서 Redis와 비교할 때 훨씬 더 다양한 기능을 제공한다.
크고 복잡한 메시지에 적합하다.


<mark>나는 뉴스기사를 짧은간격으로 자주 수집해오는것을 목표</mark>로 하였기때문에, 약간의 데이터손실을 감당하고 빠른 속도가 장점인 Redis를 airflow에 적용시켰다.

## AirFlow 

Airflow는 오픈소스 워크플로 관리 플랫폼이다. 아파치 재단에서 만들었고, 파이썬으로 작성되어있으며 워크플로우를 작성할때 파이썬 스크립트를 통해 만들어진다.

Airflow를 접하다보면 <u>워크플로우</u>, <u>DAG</u>,<u>스케줄,스케줄링</u> 라는 단어를 많이 접하게된다. 이것들은 Airflow를 구성하는 아주 기본적인것들이며 Airflow를 사용하게된다면 좋든 싫든 친해져야할 친구들이다.


그럼 Airflow에대해서 상세하게 알아보자.

Airflow는 워크플로우 스케줄링(주기적으로 자동화시키길 원하는 스케줄의 관리)와 감시(모니터링)를하는 기능을 제공한다.

Airflow의 이름을 떠올려보면 이 도구가 뭐하는 도구인지 잘 알수있다.
바람개비인데 바람개비가 바람이불면 순차적으로 돌아가는것처럼 우리가 자동으로 작업되길 원하는 스케줄을 파이썬 스크립트파일을 통해 워크플로우( 의존성으로 연결된 작업들의 집합.)를 작성하면 Airflow가 이 워크플로우를 알아서 관리하고 실행시키고 모니터링한다.

Airflow가하는 역할을 예를들어본다면 이런거다.

우리는 알아서 식사시간이되면 식사를한다.
우리는 사람이기떄문에 알아서 때가되면 요리를하고 음식을만들고 음식을먹는 행동을한다.

**하지만 컴퓨터는 다르다.** 이 친구는 똑똑한것같으면서도 바보이기때문에 우리가 밥을먹으라고 명령을내려야 밥을먹는다.
하지만 이친구는 밥을먹으라고하면 정말 밥만먹는다. 먹을 밥이없으면 밥을만드는 그 전 단계를 처리하지않고 되려 오류를 발생시킨다.

*예를들면, 에러:먹을밥이없습니다. 이런식으로 말이다.*

그러면 우리(사용자)는 컴퓨터에게 하나하나 모든 작업을 스크립트파일로 명령을 내려줘야한다. 

요리 > 밥먹기 

이렇게보면 두개밖에없으니까 괜찮을것같지만 이런일을 매일매일, 식사뿐만아니라 우리가 하루를 보내듯 많은일을 시키려면 굉장히 번거로운 작업이될것이다.

그런것을 한번의 명령으로 컴퓨터가 알아서 동작하게하는것을 도와주는게, **Airflow**다.

단어를 조금 자세하게 살펴보자.

#### 개념 및 단어

- 워크플로우 : 의존성으로 연결된 작업들의 집합. 마트에가서 식자재를 사서와야 요리를할수있고, 요리를해야 점심식사를 할수있다. 이러한 작업들의 집합을 의미한다.

- DAG : 방향이 있는 순환되지않는 그래프(Directed Acyclic Graph)의 약자로 DAG라고 말한다. Task들의 집합이고, 작업집합의 그래프이기때문에 파이프라인으로 볼수있다. 점심식사를하기까지의 전체적인 흐름이라고 보면된다.
  
- Task : 아주작은 작업의 단위이다. 예를들면 마트에서 양파를사오기, 마트에서 계산을하기, 마트에서 장바구니를 구입하기 이런것들 하나하나가 각각의 Task가된다. 그리고 이 Task가 모여서 마트에서 장을보고 나오기 라는 하나의 DAG가 된다.


#### 에어플로우 구성요소

- Airflow_user: 나 (컴퓨터가밥먹길원하는사람)

- 웹서버 : 컴퓨터가 user가시킨 식재료를 제대로 사고있는지, 조리법대로 요리하고있는지 등을 감시하고 관리해서 내게 정보를 제공하는 화면. 내가 직접 컴퓨터에게 명령을 내려도 되지만, 웹 서버에게 명령을 내려도된다.

- 스케줄러 : 워크플로우 시간 관리 담당 비서같은녀석

- 메타스토어 : 여러 DAG들의 정보를 기록해놓은 파일함같은것. 해당 DAG가 왜 실패했는지, 어디서 문제가생겼는지 어떤 오류를 반환했는지를 기록한다.

- 익스큐터 : 작업을 배치하는 작업반장 역할을하는 친구이다. Airflow의 환경설정에서 바꿔줄수있다.

- 워커 : 작업반장에게서 작업을 할당받아서 일을해주는 친구. 

- 오퍼레이터 : 특정 작업을 수행할때 사용되는 기계같은것이다. 식기세척기를 떠올리면 적합하다. 이 오퍼레이터들을 이용하면 하나의 task가될수있다. (DAG:설거지, TASK:접시를닦기, 숟가락을 닦기, Operator:식기세척기) 이런식으로 이해하면 편하다.

<mark>예시</mark>

    with DAG :

        TASK_1:(
            식기세척기 오퍼레이터:
                숟가락 닦기
                ..
                .
        )

        TASK_2:(
            건조기 오퍼레이터:
                접시말리기
                ..
                .
        )

    TASK_1 >> TASK_2  # 이 친구는 DAG의 방향, 즉 파이프라인의 흐름을 지정하는것. 이것까지 완성해줘야 진정한 하나의 DAG가 완성된다.

DAG의 종류로는 

-generic_transfer : sql를 다룰때 주로 사용한다. airflow에서 수집, 가공되고있는 데이터를 지정한 db에 작성한 sql문을 실행하고 적재한다.

-Dummy : 아무작업도 하지않는 연산자로 다른 작업을 그룹화하는데 사용되는 오퍼레이터.

-＊Sensor : Task를 언제 실행시킬 트리거를 기다리는 특별한 오퍼레이터. (어떤 폴더에 데이터가 쌓이고있는지, hdfs에 내가 찾는 폴더나 파일이있는지 등을 감지하는 작업을하는 오퍼레이터)

-PythonOperator : 파이썬 코드, 함수등을 작업하게 도와주는 오퍼레이터.

-BashOperator : bash 명령어를 사용할수있도록 도와주는 오퍼레이터.

-sqlOperator :  sql 관련 작업들을 도와주는 오퍼레이터이다. 

-SimpleHttpOperator : HTTP요청을 보내고 응답 텍스트를 받는 작업을한다.

-HttpSensor : 응답(response)하는지 확인할 때 사용하는 센서 기계

간단하게 위와같은 오퍼레이터 및 센서들만 알아도 어느정도 작업은 다 처리할수있다. 


[Operator_정리](https://yhjin.tistory.com/26)

### Connections

ssh, sql 연동 정보등을 생성 및 등록하여 고유한 id로 연동정보를 불러서 사용한다.

웹서버에서 Admin->Connections 를 통해 등록할수있다.

자세한건 해당 페이지의 Airflow.md를 참조하자.


## Hadoop

하둡을 한줄로 요약하고 설명하자면 **일반수준의 PC 여러대를 하나의 가상 스토리지로 만들어서 스토리지안에 저장된 빅데이터를 병렬처리해줄수있게하는 오픈소스 프레임워크이다** 

그러나 이렇게 말한다면 조금 하둡이라는 녀석을 알기어렵다.

그렇다면 하둡이 어떻게쓰이는지, 왜 하둡이 탄생하였는지를 보면 이녀석의 역할을 잘 알수있을것이다.

#### 하둡의 탄생배경

하둡의 등장은 시대가변하면서 데이터의 타입과 크기가 다양해지고 커지면서 하둡이 등장하게되었다. <u>일반 디스크같은경우는</u> 데이터를 저장할수있는 용량은 크지만 <u>읽는속도는 초당 100MB</u>로, 만약 하드디스크에 저장된 <u>1TB짜리 데이터를 읽는다고친다면 약 두시간이걸릴것이다.</u>

그렇다면 기업에서는 하루에 많은일을 처리하지못하게될것이다. 그러한 문제를 해결하기위해 나온것이 하둡이다.

만약 1TB 크기의 데이터를 100개로 쪼개서 100개의 디스크에 각 100분의 1만큼씩의 데이터를 저장했다고 가정한다면, 크기가 작은 데이터를 불러오는것이기때문에 2분이면 충분히 데이터를 읽어올수있을것이다.

그렇게 데이터를 쪼개서 하둡 클러스터에 저장하는 파일시스템을 HDFS라고하고, 쪼개진 데이터를 계산이나 조작하는것을 도와주는친구가 맵리듀스라고 생각하면된다. 

즉, 하둡은 여러대의 저장소를 하나로 묶어, 하나의 저장소처럼 사용하며 데이터의 분산 저장 및 처리를 도와주는 오픈소스 프레임워크라고 생각하면된다. 

기본적으로 구조는 

HDFS : 하둡파일 시스템.

맵리듀스 : 일괄 질의 처리기. 일괄로 처리하기때문에 짧은 시간내에 응답을 돌려받진못한다. HDFS에 저장된 큰 데이터를 계산하고 처리하는 역할을한다.JSON포맷으로 데이터를 처리한다. (키-밸류) 여튼 핵심은 계산이 맵과 리듀스로 분리되어있고 그 둘 사이를 혼합해주는 인터페이스가 존재한다는것.

YARN : 하둡 클러스터의 자원 관리시스템이다. YARN이 있으므로 맵리듀스뿐만아니라 **어떤분산처리 프로그램도 하둡 클러스터에 저장된 데이터를 처리할수있게해준다.**


으로 이루어져있다.


이러한 하둡은 **하둡에코시스템** 이라고해서 하둡과 함께사용하는 타 프레임워크들과 생태계를 이루어서 살아가고있다고 보면된다.

(하둡이 코끼리이고 하둡을 사용하는 사람들이 자신의 프레임워크의 이미지를 꿀벌, 돼지 등으로 해서 동물원을 연상시킨다고 하둡에코시스템이라고 부른다. 그리고 주키퍼는 말그대로 이것들의 사육사, 즉 관리자역할을하는 프레임워크가되는것이다.)

하둡은 타 프레임 워크들과 함께 작동할때 더욱 좋지만, 우리는 일단 하둡이라는녀석을 알아봐야하기때문에 위에서 언급한 하둡의 기본구성 **(HDFS, 맵리듀스 , YARN)** 을 알아볼것이다.

#### HDFS

위에서도 언급했듯이 하둡은 아주 큰 빅데이터를 하둡 클러스터에 분산저장하여 관리하고 잘 정리정돈하는 친구이다.

그렇기때문에 하둡에 파일을 저장하면 **하둡은 블록단위로 데이터를 저장하게되고**, 이 블록은 한개당 128MB 크기를 가진다. 왜 128MB이냐면 우리는 어떤 크기의 비정형,정형 데이터를 저장할지 모르고 가장 계산하기 쉬운 단위가 128MB이기때문에 기본적으로 128MB로 설정되어있는것이다.

블록의 크기는 **hdfs-site.xml의 dfs.blocksize 속성**을 사용해서 바이트 단위로 설정해줄수있다. (256,268,435,465등등.. 네임노드의 메모리부담을 줄이면서 매퍼가 더많은 데이터를 처리할수있도록하는것이다.)

#### NameNode

하둡은 분산처리시스템이기때문에 '어떤곳에 어떻게 저장하고 관리할것인가'를 담당하는 관리자가 꼭 필요하다.

그러한 역할을하는것을 보통 MasterNode라고 표현하고 HDFS에서는 NameNode, 맵리듀스에서는 Job Tracker 라고 부른다. (Task Tracker는 DataNode와 같은개념 다만 맵리듀스에서 사용하는 단어이다.)

즉, **NameNode**는 해당서버에 워커로 등록된 DataNode들을 관리하는 *마스터*인것이다.

NameNode는 DataNode에게 저장해야할 데이터를 분배하는 역할을하는것이다.

얼만큼의 크기의 블록으로 들어오는 데이터를 쪼갤것인지, 들어오는 데이터에대해서 복제본을 몇개를 생성할지 이러한것들을 정해서 DataNode에게 저장하라는 명령을 내리는것이다.

<u>NameNode의 역할 간단하게 정리</u>

- 메타 데이터 관리 : 파일 시스템을 유지하기 위한 메타데이터를 관리함
- 데이터노드 모니터링 : 3초마다 Hart-beat를 전송한다(워커가 동작중인지 주기적으로 확인해야하니까) DataNode도 NameNode에게 Hart-beat를 전송함으로 서로간에 주고받는다. 10분이상 반응이없을시 NameNode는 DataNode가 죽었다고 판단한다.
- 블록관리 : 장애가 발생한 데이터노드가있을수있으니 복제. 어떤 파일이 어떤 블록으로 어떤 데이터노드에 저장되어있는지 기록한 장부같은것도 가지고있음. 그걸보고 파일을 반환함

※메타데이터란?

전체적인 구조를 뜻함. 파일시스템이 어떤 구조로 이루어져있는지에 대한 전체적인 관리를 NameNode가함

#### DataNode

NameNode가 마스터노드였다면 DataNode는 워커노드이다. 관리는하지않고 NameNode에게서 전달받은 데이터를 지정된 블록단위만큼 쪼개서 저장하고 지정된 복제본의 갯수만큼 백업용으로 복제해서 가지고있는다.

여기서 복제본 같은경우는 같은 DataNode에 저장되지않는다. 다른 DataNode과 복제본을 나눠갖게되는 구조이다.

지정된 블럭의 단위만큼 파일을 쪼개서 관리하되, 하나의 원본을 저장하되 지정한 갯수만큼의 복제본을 같은 rack에도 저장하고 다른 rack에도 저장하는 방식으로 저장이된다.

그렇다면 HDFS에는 한개의 원본 + 지정한 복제본 만큼의 쪼개진 블럭을 나눠가지게되는것이다.



![hdfs의저장방식](./Hadoop/hdfs저장방식.PNG)

▲ 위와 같은 구조가되는것이다.

파일을 쪼개서 A B C 가나왔다고 친다면 RACK1의 데이터노드1번에 A블럭 저장(원본) RACK1의 데이터노드2에 A블럭 저장(사본) RACK2의 데이터노트3번에 A저장(사본2)


그럼 여기서 이런 생각이든다. <u>'엥 굳이 복제본을?'</u>

이유는 간단하다. 여기저기 분산해서 저장해놨는데 하나의 노드가 고장이나버렸다고 가정하자.

만약 이런상황에 복제본을 만들어놓지않았다면 문제가생길것이다.

HDFS에서 복제본을 지정하고 여러 DataNode에 저장하는이유가 바로 이것이다. HDFS는 복제본을 여러곳에 저장함으로써 안정성을 보장한다.

<u>DataNode 역할 간단하게 정리</u>

- 클라이언트가 HDFS에 저장하는 파일을 로컬 디스크에 유지
- 실제 데이터를 저장하는역할

#### 맵리듀스

이 친구는 HDFS에 저장된 데이터를 계산 및 처리하는 역할을한다.
하지만 아까 위에서도 말했듯이 일괄 질의 처리기고 이녀석은 RDBMS와 좀 다르다. RDBMS는 상대적으로 크기가 작고  **정형데이터** 를 처리하는데 특화되어있다는 강점을 가지고있다. 그러므로 특정 쿼리와 데이터를 변경하는데 적합하다 (상대적으로 크기가작은)

또한 분산처리되어있는 데이터를 다시한곳으로모아 통합처리를한다면, 데이터를 계산하거나 처리하는데 매우 많은 시간이 들고 비효율적이게된다.

그래서 맵리듀스는 각각의 노드에서 처리를한 결과를 통합하는것이다.

각각의 처리는 맵이하고 리듀스는 통합하여 결과를 반환한다. 그리고 그 리듀스의 출력값을 중앙에 넘겨주는 흐름이다.

하지만 시대는 '빅데이터'라는 단어가 생겨날만큼 데이터의 크기가 커졌다.
수집되는 데이터는 정형데이터가아니라 이미지, 동영상, 텍스트 등 비정형 데이터가 주를 이루면서 수집되고 이동되는 데이터의 크기가 늘어나버린것이다.

빅데이터: 1024TB는 1PB(페타 바이트)가 된다. 일반적인 빅데이터는 현재 페타 바이트 단위이다.

데이터의 단위 : 비트(yes or no) < 1바이트(알파벳1 숫자1) < 1킬로바이트kb(몇개의 문단) < 메가바이트mb(1분길이의 mp3노래) < 1기가바이트 (30분 길이의 HD영화) < 1테라바이트(195~200편의 FHD영화) < 1페타바이트pb 

※ 1024배씩 단위가 커진다. 1바이트는 1024비트, 1기가바이트는 1024메가바이트.

RDBMS와 맵리듀스의 차이를 표로 표현한다면

|구분|RDBMS|맵리듀스|
|:-----:|:-----:|:----:|
|데이터크기|기가바이트|페타바이트|
|접근방식|대화형과 일괄 처리방식|일괄 처리방식|
|변경|여러번 읽고 쓰기|한번 쓰고 여러번 읽기|
|트랜잭션|ACID(원자성,일관성,고립성,지속성)|없음|
|구조|쓰기 기준 스키마|읽기 기준 스키마|
|무결성|높음|낮음|
|확장성|비선형|선형|


맵리듀스는 크게 맵(매퍼) / 리듀스로 단계로 나눠져있다. 

각 단계는 입-출력 으로 나눠져있고 JSON파일형식으로 데이터를 처리한다.

맵 단계에서 입력,처리하여 출력한 값은 리듀스가 입력으로 건네받게되고, 리듀스는 사용자가 지정한 리듀스단계에서 수행해야할 일을하여 최종적으로 결과물을 출력하게된다.

그럼 어떤 단계에 어떤 작업을 맡기는게 좋을까?

맵 단계에서는 주로 **이상치** (결측값, 문제가있는 값이나 레코드 등)를 걸러주는 작업을 수행하는것이 적합하다.
이렇게 걸러진 JSON값들을 리듀스의 입력값으로 넘겨서 리듀스는 깨끗한 데이터세트에서 우리가원하는 값을 찾아 출력하게된다.

단, 맵 -> 리듀스 단계로 넘어가는 과정에서 JSON값들은 KEY를 기준으로 정렬되고 그룹화하게된다.

    EX) 

    #맵 출력
    

    (1950, 11)
    (1950, 12)
    (1950, 03)
    (1821, 01)
    (1822, 07)
    (1821, 05)

    #리듀스 입력
    #reduce (key, list(value))

    (1821, [01,05])
    (1822, [07])
    (1950, [11,12,03])



맵에서 리듀스로 넘어가는 단계에서 위와같은 작업이 이루어진다. 아까 말했던것처럼 KEY를 기준으로 정렬되고 그룹화하게되는것이다.

그렇다면 내가 만약 리듀스 단계에서 각 년도가 가지고있는 가장 마지막달을 구하는 함수를 작성하였다면, 리듀스 단계에서는 위와같이 입력받고 아래와같이 출력하게된다. 
    

    (1821, 05)
    (1822, 07)
    (1950, 12)


이제 맵리듀스가 뭘하는 친구인지 간단하게 알아보았다. 맵단계에서 입력할때, 어떤 데이터를 어떤 타입으로 넣을지는 사용자가 정할수있다.
각 행의 타입을 텍스트로 인식하는 텍스트 입력 포맷을 선택하면 텍스트이면서 키-값 의 형태를 가지게된다.




#### 하둡의 주요 단어

-노드 : 하나의 컴퓨터. 하나의 서버. 즉 클러스터로 묶을수있는 구성원. 30~4-개의 노드가모여 하나의 rack을 이룬다.

-rack : 노드들이 모여 하나의 rack을 이룬다. rack은 물리적으로 같은 네트워크의 스위치에 모두 연결되어있다. 데이터의 이동할수있는 폭이 크기때문에 속도가 빠르다.

-하둡클러스터 : 여러개의 rack이 모여 만들어진 거대한 하나의 가상스토리지.

-YARN클러스터

-탐색 : 디스크상에서 탐색이라는것은 데이터를 읽거나 쓸 때 디스크의 헤더를 디스크의 특정위치로 이동시키는 조작이다. 디스크의 전송속도는 디스크의 대역폭과 관계가있다. 대역폭이 작을수록 데이터를 읽어오거나 작성하는데 시간이 줄어든다.

-B트리 : 관계형 데이터베이스에서 사용되는 자료구조이다. 탐색을 수행하는 속도에 제한이있다. 데이터베이스의 상당 부분을 변경할때 B-트리는 데이터베이스를 재구성하기위해 소트와 머지를 사용해야하므로 맵리듀스보다 비효율적이다. 이것이 빅데이터를 RDB에서 처리하는것이 비효율적인 이유이다.


## 단어

-데이터 마이닝 : 결과를 예측하기위해 대용량 데이터세트에서 의미있는 패턴이나 통계적 규칙을 찾아내는것.

-데이터 파이프 라인

-ETL

-UDP

-TCP

-정형 데이터 : 날짜, 시간 및 고객 ID같이 미리 정의된 특정 스키마를 가진 데이터베이스 테이블과 같이 형식이 정해진 항목으로 구조화되어있음.값과 숫자로 구성되어있다. 의미파악이 쉽고, 규칙적으로 입력되는값을 정형 데이터라고 볼수있다. (데이터베이스에 들어가있는 값이라고 다 정형은아니다)

-반정형 데이터 : 정형데이터에 비해 스키마가 유연하거나 생략되있을수있다. 데이터 구조에대한 최소한의 규칙만있으면된다. 그리드 형태의 셀 구조로된 스프레드시트는 셀 자체에 어떤 형태의 데이터도 담을수있는것처럼말이다. 비정형과 반정형이 섞인것이다. JSON 형식을 예로 들어본다면 json형식의 글 내용본문은 반정형이다(비+정 섞임), db에 저장된 글제목 > 비정형, db에 저장된 성별 > 정형

-비정형 데이터 : 어떠한 내부 구조가없는것. 일반 텍스트나 음성 이미지 영상 등 아무런 규칙도 구조도 없는 데이터들을 의미한다.

-선형

-비선형






