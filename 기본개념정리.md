# 프로젝트를 진행하면서 사용한 기술스택들에대한 기본 개념정리

많지는않지만 프로젝트들을 진행하면서 여러 기술들을 사용하게되었다.
보통 프로젝트에 기술을 적용하면서 바로바로 기본개념들을 간단하게 정리해놨지만 기술들의 갯수가 많아지고 프로젝트에 적용시키면서 트러블슈팅들을 같이 작성해놓으니까 찾아보기가 힘들어지는 문제점이생겼다.

그래서 프로젝트에 이용했던 기술 스택들에대한 기본 개념들을 이곳에 정리해놓고 필요할때 찾아보는편이 낫겠다고 판단하여 작성.

- Celery
- Redis
- Airflow
- Django
- GCP
- Kafka
- Hadoop & hdfs
- Spark
- Elastic search
- logstash
- Kibana 
- SQL
- Nginx
- uWsgi
- Zookeeper
- Pandas
- Numpy
- Docker
- CloudFlare
## Celery와 사용이유

Celery는 많은 작업을 분산처리를 할 수있도록 해주는 Task queue이다. <u>Task는 비동기 처리를 도와주는 친구로 Celery는 비동기 작업 큐 라고 생각하면된다.</u>

<u>그럼 비동기 작업이 왜 필요한가?</u> 

이건 간단하게 생각하면 쉽다.
예를 들어 내가 스타벅스의 매장을 조회하기위하여 스타벅스 홈페이지에 접속하여 매장 조회를 눌렀다고 가정하자.

그런데 웹 페이지의 경우, 전국의 스타벅스 매장의 정보를 DB에서 가져오기때문에 이 가져오는 작업이 끝날때까지 나는 하염없이 웹 페이지의 응답을 기다려야한다.

그래서 그러한 무거운 연산 및 처리들을 Task라는 비동기 작업을 처리해주는 큐에 넘겨주고, 이용자는 다른작업을 할 수 있도록하는것이 원리이다.
그런고로 Celery는 클라이언트와 worker사이를 중재하는 메세지 브로커를 사용하여 통신하게되는데, worker들에게 task를 처리하도록 시키기위해 메세지 브로커로써 Redis나 Rabbit MQ를 사용하게된다.


그럼 queue는 뭘까? 이건 컨테이너벨트에 적재된 화물을 생각하면 쉽다.
예를들어, 택배사에서 컨테이너 벨트위에 배송되야할 택배들이 줄지어있다고치면 이 화물들이 처리해야할 작업이되는것이고 큐는 컨테이너벨트가되는것이다.

그러면 컨테이너벨트에 택배(화물)을 올려주는 작업을해주는 친구가 필요한데, 그 역할을하는게 시스템 브로커이다.

클라이언트에서 처리해야할 작업(task)를 생성하면 celery는 브로커를 통해 worker들에게 메세지를 전달하여 worker들이 해당 작업을 처리하게한다.

celery는 1분에 수백만건의 task를 처리할수있는 속도를 제공하기때문에 분산작업 처리를할때 유용하다.

보통 Airflow+celery+redis or rabbit mq를 많이 사용한다.

## Redis

<u>Airflow와 Redis</u>

redis를 airflow와 함께 사용할때는 보통 메세지 브로커로써 활용한다.
하지만 Redis의 태생 자체가 메세지 브로커가아니라 인 메모리 db로, <u>Key-value형식을가진 Nosql에 속하는 자료구조 서버이다</u>

우리가 흔히 사용하는 DB는 데이터를 물리 디스크에 직접써서 요청,쿼리가 발생할때마다 디스크에 접근하여 데이터를가져온다.
이러한 방법은 <u>서버에 장애가 발생하여도 데이터가 손실되지않는다.</u>

하지만 단점이있다.
사용자가 늘어가서 데이터베이스에 요청되는 쿼리가 커지고 많아진다면 디스크에 접근하는 횟수도 많아지기때문에 DB에 부하가발생하고 속도가 현저히 느려진다.

이때 캐시(메모리 기반) 서버를 도입하게되는데 이 Redis라는것이 인 메모리 DB이다.

캐시서버의 특징은 한번읽어온 데이터를 임의의 공간에 저장하여 다음에 읽을때 새로 읽어오는게 아니라 저장하고있던 정보를 빠르게 받아볼수있게 도와준다.

캐시서버가 한번 읽어온 데이터를 임의의 공간에 저장하고있기때문에, 당연히 매번 데이터베이스를 거치지않기때문에 DB의 부하를 줄이고 서비스 속도도 느려지지않는 장점이있다.

Airflow에서 redis를 같이쓰게되면 redis가 메세지 브로커로써 클라이언트가 생성한 Task가 지정된 큐에따라 redis서버안에 Key-Value타입으로 쌓이는것을 확인할수있다.

만약 내가 airflow task에 큐를 worker-1이라고 지정해놓으면 celery worker를 실행시킬때 워커가 모니터링할 큐를 worker-1이라고 지정해놓으면 해당 worker가 redis 큐 안의 task를 순차적으로 처리하게된다. 

redis 큐 안에 적재되는 task는 <u>task id</u>라는 고유한 task 아이디값이 있어서 아이디 값에따라 순차적으로 처리되는것을 확인할수있었다.

그렇다면 기본 Redis에 대해서 조금 더 알아보자.

Redis의 Key값의 자료형은 String형이지만 Value값의 자료형은 다양한 타입을 지원한다.

서버가 1개라면 굳이 Redis를 사용할필요는없겠지만(인 메모리 데이터베이스로써), 분산환경에서라면 원격 프로세스간의 데이터를 일치시키기가 Redis가 더욱 편리하다.

Redis의 단점은 무엇일까?

1.메모리 기반 DB이기때문에 서버에 장애가 발생했을시 데이터의 유실이있다.

2.메모리 기반 DB이기떄문에 메모리관리가중요하다.

3.싱글 스레드의 특성상, 처리하는데 시간이 오래걸리는 요청이나 명령은 비효율적이다.

### Redis VS Rabbit MQ

둘다 Airflow에서 메세지 브로커로 주로 활용된다.

두가지 다 Airflow와 사용하기 좋지만, 조금씩 특징이 다르다.

<u>Redis</u>

Key-Value를 이용해 Celery가 처리할 작업을 Celery에 보낸 후 캐시에서 해당 Key를 제거하는 방식으로 작동한다.

1.Redis는 데이터 검색을 위해 Database에 접근하기 전 메모리에서 Cache를 가져다 쓴다는 점에서 속도가 빠르다.

2.매우 빠른 서비스 및 메모리 내 기능을 제공하기 때문에 지속성이 중요하지 않고 약간의 손실을 견딜 수있는 짧은 보존 메시지에 적합하다.

3.큰 메시지를 처리 할 때는 대기 시간이 오래 걸린다.


<u> Rabbit MQ</u>

응용 프로그램(applications)에게 메시지를 주고 받을 수 있으며, 메시지가 수신될 때까지 안전하게 있을 수 있도록 하는 공용 플래폼(common platform)을 제공한다.

1.메시지를 다른 대기열로 보낼 수있는 라우팅 시스템을 갖추고 있다.

2.우선 순위가 높은 메시지를 먼저 사용하기 위해 작업자가 사용할 수있는 메시지의 우선 순위를 지원한다.

3.메시지 브로커로서 Redis와 비교할 때 훨씬 더 다양한 기능을 제공한다.
크고 복잡한 메시지에 적합하다.


<mark>나는 뉴스기사를 짧은간격으로 자주 수집해오는것을 목표</mark>로 하였기때문에, 약간의 데이터손실을 감당하고 빠른 속도가 장점인 Redis를 airflow에 적용시켰다.

## AirFlow 

Airflow는 오픈소스 워크플로 관리 플랫폼이다. 아파치 재단에서 만들었고, 파이썬으로 작성되어있으며 워크플로우를 작성할때 파이썬 스크립트를 통해 만들어진다.

Airflow를 접하다보면 <u>워크플로우</u>, <u>DAG</u>,<u>스케줄,스케줄링</u> 라는 단어를 많이 접하게된다. 이것들은 Airflow를 구성하는 아주 기본적인것들이며 Airflow를 사용하게된다면 좋든 싫든 친해져야할 친구들이다.


그럼 Airflow에대해서 상세하게 알아보자.

Airflow는 워크플로우 스케줄링(주기적으로 자동화시키길 원하는 스케줄의 관리)와 감시(모니터링)를하는 기능을 제공한다.

Airflow의 이름을 떠올려보면 이 도구가 뭐하는 도구인지 잘 알수있다.
바람개비인데 바람개비가 바람이불면 순차적으로 돌아가는것처럼 우리가 자동으로 작업되길 원하는 스케줄을 파이썬 스크립트파일을 통해 워크플로우( 의존성으로 연결된 작업들의 집합.)를 작성하면 Airflow가 이 워크플로우를 알아서 관리하고 실행시키고 모니터링한다.

Airflow가하는 역할을 예를들어본다면 이런거다.

우리는 알아서 식사시간이되면 식사를한다.
우리는 사람이기떄문에 알아서 때가되면 요리를하고 음식을만들고 음식을먹는 행동을한다.

**하지만 컴퓨터는 다르다.** 이 친구는 똑똑한것같으면서도 바보이기때문에 우리가 밥을먹으라고 명령을내려야 밥을먹는다.
하지만 이친구는 밥을먹으라고하면 정말 밥만먹는다. 먹을 밥이없으면 밥을만드는 그 전 단계를 처리하지않고 되려 오류를 발생시킨다.

*예를들면, 에러:먹을밥이없습니다. 이런식으로 말이다.*

그러면 우리(사용자)는 컴퓨터에게 하나하나 모든 작업을 스크립트파일로 명령을 내려줘야한다. 

요리 > 밥먹기 

이렇게보면 두개밖에없으니까 괜찮을것같지만 이런일을 매일매일, 식사뿐만아니라 우리가 하루를 보내듯 많은일을 시키려면 굉장히 번거로운 작업이될것이다.

그런것을 한번의 명령으로 컴퓨터가 알아서 동작하게하는것을 도와주는게, **Airflow**다.

단어를 조금 자세하게 살펴보자.

#### 개념 및 단어

- 워크플로우 : 의존성으로 연결된 작업들의 집합. 마트에가서 식자재를 사서와야 요리를할수있고, 요리를해야 점심식사를 할수있다. 이러한 작업들의 집합을 의미한다.

- DAG : 방향이 있는 순환되지않는 그래프(Directed Acyclic Graph)의 약자로 DAG라고 말한다. Task들의 집합이고, 작업집합의 그래프이기때문에 파이프라인으로 볼수있다. 점심식사를하기까지의 전체적인 흐름이라고 보면된다.
  
- Task : 아주작은 작업의 단위이다. 예를들면 마트에서 양파를사오기, 마트에서 계산을하기, 마트에서 장바구니를 구입하기 이런것들 하나하나가 각각의 Task가된다. 그리고 이 Task가 모여서 마트에서 장을보고 나오기 라는 하나의 DAG가 된다.


#### 에어플로우 구성요소

- Airflow_user: 나 (컴퓨터가밥먹길원하는사람)

- 웹서버 : 컴퓨터가 user가시킨 식재료를 제대로 사고있는지, 조리법대로 요리하고있는지 등을 감시하고 관리해서 내게 정보를 제공하는 화면. 내가 직접 컴퓨터에게 명령을 내려도 되지만, 웹 서버에게 명령을 내려도된다.

- 스케줄러 : 워크플로우 시간 관리 담당 비서같은녀석

- 메타스토어 : 여러 DAG들의 정보를 기록해놓은 파일함같은것. 해당 DAG가 왜 실패했는지, 어디서 문제가생겼는지 어떤 오류를 반환했는지를 기록한다.

- 익스큐터 : 작업을 배치하는 작업반장 역할을하는 친구이다. Airflow의 환경설정에서 바꿔줄수있다.

- 워커 : 작업반장에게서 작업을 할당받아서 일을해주는 친구. 

- 오퍼레이터 : 특정 작업을 수행할때 사용되는 기계같은것이다. 식기세척기를 떠올리면 적합하다. 이 오퍼레이터들을 이용하면 하나의 task가될수있다. (DAG:설거지, TASK:접시를닦기, 숟가락을 닦기, Operator:식기세척기) 이런식으로 이해하면 편하다.

<mark>예시</mark>

    with DAG :

        TASK_1:(
            식기세척기 오퍼레이터:
                숟가락 닦기
                ..
                .
        )

        TASK_2:(
            건조기 오퍼레이터:
                접시말리기
                ..
                .
        )

    TASK_1 >> TASK_2  # 이 친구는 DAG의 방향, 즉 파이프라인의 흐름을 지정하는것. 이것까지 완성해줘야 진정한 하나의 DAG가 완성된다.

DAG의 종류로는 

-generic_transfer : sql를 다룰때 주로 사용한다. airflow에서 수집, 가공되고있는 데이터를 지정한 db에 작성한 sql문을 실행하고 적재한다.

-Dummy : 아무작업도 하지않는 연산자로 다른 작업을 그룹화하는데 사용되는 오퍼레이터.

-＊Sensor : Task를 언제 실행시킬 트리거를 기다리는 특별한 오퍼레이터. (어떤 폴더에 데이터가 쌓이고있는지, hdfs에 내가 찾는 폴더나 파일이있는지 등을 감지하는 작업을하는 오퍼레이터)

-PythonOperator : 파이썬 코드, 함수등을 작업하게 도와주는 오퍼레이터.

-BashOperator : bash 명령어를 사용할수있도록 도와주는 오퍼레이터.

-sqlOperator :  sql 관련 작업들을 도와주는 오퍼레이터이다. 

-SimpleHttpOperator : HTTP요청을 보내고 응답 텍스트를 받는 작업을한다.

-HttpSensor : 응답(response)하는지 확인할 때 사용하는 센서 기계

간단하게 위와같은 오퍼레이터 및 센서들만 알아도 어느정도 작업은 다 처리할수있다. 


[Operator_정리](https://yhjin.tistory.com/26)

### Connections

ssh, sql 연동 정보등을 생성 및 등록하여 고유한 id로 연동정보를 불러서 사용한다.

웹서버에서 Admin->Connections 를 통해 등록할수있다.

자세한건 해당 페이지의 Airflow.md를 참조하자.


## Hadoop

하둡을 한줄로 요약하고 설명하자면 **일반수준의 PC 여러대를 하나의 가상 스토리지로 만들어서 스토리지안에 저장된 빅데이터를 병렬처리해줄수있게하는 오픈소스 프레임워크이다** 

그러나 이렇게 말한다면 조금 하둡이라는 녀석을 알기어렵다.

그렇다면 하둡이 어떻게쓰이는지, 왜 하둡이 탄생하였는지를 보면 이녀석의 역할을 잘 알수있을것이다.

#### 하둡의 탄생배경

하둡의 등장은 시대가변하면서 데이터의 타입과 크기가 다양해지고 커지면서 하둡이 등장하게되었다. <u>일반 디스크같은경우는</u> 데이터를 저장할수있는 용량은 크지만 <u>읽는속도는 초당 100MB</u>로, 만약 하드디스크에 저장된 <u>1TB짜리 데이터를 읽는다고친다면 약 두시간이걸릴것이다.</u>

그렇다면 기업에서는 하루에 많은일을 처리하지못하게될것이다. 그러한 문제를 해결하기위해 나온것이 하둡이다.

만약 1TB 크기의 데이터를 100개로 쪼개서 100개의 디스크에 각 100분의 1만큼씩의 데이터를 저장했다고 가정한다면, 크기가 작은 데이터를 불러오는것이기때문에 2분이면 충분히 데이터를 읽어올수있을것이다.

그렇게 데이터를 쪼개서 하둡 클러스터에 저장하는 파일시스템을 HDFS라고하고, 쪼개진 데이터를 계산이나 조작하는것을 도와주는친구가 맵리듀스라고 생각하면된다. 

즉, 하둡은 여러대의 저장소를 하나로 묶어, 하나의 저장소처럼 사용하며 데이터의 분산 저장 및 처리를 도와주는 오픈소스 프레임워크라고 생각하면된다. 

기본적으로 구조는 

HDFS : 하둡파일 시스템.

맵리듀스 : 일괄 질의 처리기. 일괄로 처리하기때문에 짧은 시간내에 응답을 돌려받진못한다. HDFS에 저장된 큰 데이터를 계산하고 처리하는 역할을한다.JSON포맷으로 데이터를 처리한다. (키-밸류) 여튼 핵심은 계산이 맵과 리듀스로 분리되어있고 그 둘 사이를 혼합해주는 인터페이스가 존재한다는것.

YARN : 하둡 클러스터의 자원 관리시스템이다. YARN이 있으므로 맵리듀스뿐만아니라 **어떤분산처리 프로그램도 하둡 클러스터에 저장된 데이터를 처리할수있게해준다.**


으로 이루어져있다.


이러한 하둡은 **하둡에코시스템** 이라고해서 하둡과 함께사용하는 타 프레임워크들과 생태계를 이루어서 살아가고있다고 보면된다.

(하둡이 코끼리이고 하둡을 사용하는 사람들이 자신의 프레임워크의 이미지를 꿀벌, 돼지 등으로 해서 동물원을 연상시킨다고 하둡에코시스템이라고 부른다. 그리고 주키퍼는 말그대로 이것들의 사육사, 즉 관리자역할을하는 프레임워크가되는것이다.)

하둡은 타 프레임 워크들과 함께 작동할때 더욱 좋지만, 우리는 일단 하둡이라는녀석을 알아봐야하기때문에 위에서 언급한 하둡의 기본구성 **(HDFS, 맵리듀스 , YARN)** 을 알아볼것이다.

#### HDFS

위에서도 언급했듯이 하둡은 아주 큰 빅데이터를 하둡 클러스터에 분산저장하여 관리하고 잘 정리정돈하는 친구이다.

그렇기때문에 하둡에 파일을 저장하면 **하둡은 블록단위로 데이터를 저장하게되고**, 이 블록은 한개당 128MB 크기를 가진다. 왜 128MB이냐면 우리는 어떤 크기의 비정형,정형 데이터를 저장할지 모르고 가장 계산하기 쉬운 단위가 128MB이기때문에 기본적으로 128MB로 설정되어있는것이다.

블록의 크기는 **hdfs-site.xml의 dfs.blocksize 속성**을 사용해서 바이트 단위로 설정해줄수있다. (256,268,435,465등등.. 네임노드의 메모리부담을 줄이면서 매퍼가 더많은 데이터를 처리할수있도록하는것이다.)

#### NameNode

하둡은 분산처리시스템이기때문에 '어떤곳에 어떻게 저장하고 관리할것인가'를 담당하는 관리자가 꼭 필요하다.

그러한 역할을하는것을 보통 MasterNode라고 표현하고 HDFS에서는 NameNode, 맵리듀스에서는 Job Tracker 라고 부른다. (Task Tracker는 DataNode와 같은개념 다만 맵리듀스에서 사용하는 단어이다.)

즉, **NameNode**는 해당서버에 워커로 등록된 DataNode들을 관리하는 *마스터*인것이다.

NameNode는 DataNode에게 저장해야할 데이터를 분배하는 역할을하는것이다.

얼만큼의 크기의 블록으로 들어오는 데이터를 쪼갤것인지, 들어오는 데이터에대해서 복제본을 몇개를 생성할지 이러한것들을 정해서 DataNode에게 저장하라는 명령을 내리는것이다.

NameNode는 마스터 역할을하기때문에 관리자가있는 서버에 장애가생겨버리면 실제 데이터를 저장하고있는 DataNode을 사용할수없기때문에 **부하가 가장 적은 환경으로 구축**한다.

그러니, 아주 당연하게도 NameNode는 하둡클러스터 내부에있지만 하나의 Node에서 단독으로 NameNode를 실행하게된다. NameNode를 실행시키는 노드에서는 NameNode만 실행시키고 DataNode들과 같이 실행시키지않는다.

또한, NameNode에는 HDFS에 업로드한 파일이나 데이터를 실제로 저장하지않는다. (당연히 부하가 적은 환경에서 실행되고있어야하니까 데이터의 저장을 하지않는다.)

<u>NameNode의 역할 간단하게 정리</u>

- 메타 데이터 관리 : 파일 시스템을 유지하기 위한 메타데이터를 관리함
- 데이터노드 모니터링 : 3초마다 Hart-beat를 전송한다(워커가 동작중인지 주기적으로 확인해야하니까) DataNode도 NameNode에게 Hart-beat를 전송함으로 서로간에 주고받는다. 10분이상 반응이없을시 NameNode는 DataNode가 죽었다고 판단한다.
- 블록관리 : 장애가 발생한 데이터노드가있을수있으니 복제. 어떤 파일이 어떤 블록으로 어떤 데이터노드에 저장되어있는지 기록한 장부같은것도 가지고있음. 그걸보고 파일을 반환함
- 파일시스템에 이미지파일 관리(fsimage)
- 파일시스템에 대한 Edit Log관리

※메타데이터란?

전체적인 구조를 뜻함. 파일시스템이 어떤 구조로 이루어져있는지에 대한 전체적인 관리를 NameNode가 한다.

※fsimages란?

파일시스템 이미지 관리를 fsimages 라는 이름으로 NameNode가 떠있는 디스크에 저장을하게되어있다. 
이 파일은 매우매우 중요한데, 해당 이미지파일에 손상이 생길경우 하둡안의 데이터가 다 손상되는 상황이 발생할수있다.
일종의 **스냅샷**같은것.

※Edit Log

fsimages가 스냅샷같은것이라고 설명했으니, 저 스냅샷이후로 변경된 사항들이나 기타 사항들에대한것은 Edit Log에 작성된다.


#### DataNode

NameNode가 마스터노드였다면 DataNode는 워커노드이다. 관리는하지않고 NameNode에게서 전달받은 데이터를 지정된 블록단위만큼 쪼개서 저장하고 지정된 복제본의 갯수만큼 백업용으로 복제해서 가지고있는다.

여기서 복제본 같은경우는 같은 DataNode에 저장되지않는다. 다른 DataNode과 복제본을 나눠갖게되는 구조이다.

지정된 블럭의 단위만큼 파일을 쪼개서 관리하되, 하나의 원본을 저장하되 지정한 갯수만큼의 복제본을 같은 rack에도 저장하고 다른 rack에도 저장하는 방식으로 저장이된다.

그렇다면 HDFS에는 한개의 원본 + 지정한 복제본 만큼의 쪼개진 블럭을 나눠가지게되는것이다.


![hdfs의저장방식](./Hadoop/hdfs저장방식.PNG)

▲ 위와 같은 구조가되는것이다.

파일을 쪼개서 A B C 가나왔다고 친다면 RACK1의 데이터노드1번에 A블럭 저장(원본) RACK1의 데이터노드2에 A블럭 저장(사본) RACK2의 데이터노트3번에 A저장(사본2)


그럼 여기서 이런 생각이든다. <u>'엥 굳이 복제본을?'</u>

이유는 간단하다. 여기저기 분산해서 저장해놨는데 하나의 노드가 고장이나버렸다고 가정하자.

만약 이런상황에 복제본을 만들어놓지않았다면 문제가생길것이다.

HDFS에서 복제본을 지정하고 여러 DataNode에 저장하는이유가 바로 이것이다. HDFS는 복제본을 여러곳에 저장함으로써 안정성을 보장한다.

<u>DataNode 역할 간단하게 정리</u>

- 클라이언트가 HDFS에 저장하는 파일을 로컬 디스크에 유지
- 실제 데이터를 저장하는역할
- 알번적으로 레이드 구성을하지않음(패리티 체크 들어가고하면 디스크의 전체 사용용량이 줄어들어버리니까)
- 블록 리포트 : NameNode가 시작될때, 주기적으로 로컬파일시스템에있는 모든 HDFS블록들을 검사 후 정상적인 블록의 목록을 만들어 NameNode에 전송.만약 문제가있는 블록이있는것을 NameNode가 보고받는다면 해당 DataNode에게 그 블록을 지우게하고 같은 블록을 저장하고있는 다른 DataNode에게 똑같은 블록을 장애가생겼던 DataNode에게 복사하도록 명령을보낸다.

여기서 우리가 주의해야할점은 HDFS는 위에서 말한것과같이 지정된 블록단위로 쪼개서 저장하기때문에, 쪼개고 남은 용량은 지정된 블록만큼 용량을 차지하진않고 지정된 블록의크기내에서 쪼개고 남는만큼의 용량만 차지한다.


EX) 612MB 짜리 원본파일 | 블록단위 128MB 라고 치면, 128/128/128/128/100 의 용량을 가진 블록들로 나눠서 저장된다.


보통 하둡 클러스터를 구성할때 DataNode디스크는 Raid를 사용하지않는다.

(왜냐면 DataNode는 HDFS를 통해서 블록으로 쪼개진 블록파일들이 로컬디스크에 '실제로 저장'되기때문에 Raid를 하면 사용할수있는 전체 디스크 용량이 줄어드니까.)

#### 블록에대하여

하둡 2.X 부터는 블록의 기본크기가 128MB로 커졌다. 왜 블록의 단위가 커진걸까?

그건 **탐색**과 관련이있다. 탐색에대해서는 아래 하둡단어쪽에 잘 정리를해놨으나, 간단하게 말하자면 디스크에서 데이터를 찾기위해 헤더를 특정 위치로 옮기는 작업. 정도이다. 탐색의 코스트가 클수록 디스크에서 데이터를 찾아오는 속도가 느려지게된다.

그래서, 블록이 커진이유는 바로 이 **탐색 비용을 최소화하기위해**이다.

블록이 크면 하드디스크에서 블록의 시작점을 탐색하는데 걸리는 시간을 줄일수있고, 이렇게 절약한시간을 네트워크를 통해 데이터를 전송하는데 더 많은시간을 할당할수있다.


HDFS는 기본적으로 블록의 복사본을 3개를 만들도록 설정되어있다.
만약 사용자가 하둡을 설치할때 conf파일에 기본적으로 복사본을 만들 갯수를 조정해놨다면 조정한 갯수만큼의 복사본을 만든다.

이러한 복사본은 위에서 말했던것처럼 매우 중요한 역할을한다. 장애가 났을시에도 유용하지만, 결과적으로 NameNode는 DataNode에 장애가생겨서 지정해준 값만큼의 복사본을 유지할수없게되면 장애가 난 DataNode가 가지고있는 블록들의 복사본을 가지고있는 다른 DataNoode들에서 백업해놨던 복제본 블록을 복제해서 또 다른 DataNode에 복제하여 <u>블록 복제본의 갯수를 항상 일정하게 유지하게된다.</u>

그럼 HDFS에 파일을 저장하게된다면 NameNode가 DataNode에게 지정한 갯수만큼의 복사본을 나눠저장하게하라고 명령을내리고 장애가 생겼을시는 복사본의 갯수를 유지시키기위해 DataNode에게 또 다른곳에 복사하라는 명령을 내리며 관리가된다면, 아주 당연하게도 하나의 파일을 HDFS에 저장하게되면 원본파일크기*지정한복사본갯수 만큼의 용량이 필요하다는것을 알수있다.

기본 복사본 3개로 설정되어있다 가정하고 24GB짜리를 HDFS에 저장한다면 24*3 = 72GB, 72GB로 저장되는것이다.

##### 세컨더리네임노드

NameNode를 실행시키면 처음에 해당 디스크 어딘가에 저장되어있는 fsimages를 읽어서 (스냅샷같은기능) 메모리에다가 그 스냅샷을 구성을한다. 
이후 Edit Log를 쭉 읽어서 메모리에 반영을시킨다.
그러한 모든 작업을 마치면 NameNode는 실행이된다.

세컨더리 네임노드를 설명하는데 갑자기 NameNode의 설명? 이라고 생각할수도있지만, 사실 세컨더리 네임노드에 장애가 생긴다고해도 하둡 실행에는 큰 문제가없다.

다만, 위에서 말한것처럼 Edit Log 파일의 크기가 무한히 커진다는 문제점이 생긴다. (왜냐하면 계속 우리는 시스템을사용하니까 변경점이나 기타사항이 계속 log에 기록되니까.)

<u> 그럼 이 세컨더리 네임노드는 무슨 역할을 하는가?</u>

시스템에 변경점이생겼을때 Edit Log에 기록이남으니 NameNode의 fsimages와 Edit Log는 주기적으로 병합해줘서 관리를해줘야한다.
(아니면 log파일이 계속 커지니까)

하지만 병합하는 작업은 NameNode에서 실행시키지않고 세컨더리 네임노드에서 실행시킨다.

해당 데몬은 NameNode에서 Edit Log와 fsimages파일을 세컨더리 네임노드로 보내고, <u>fsimages에 Edit log 를 Merge하는 작업을 세컨더리 네임노드에서 처리하고 합쳐진 fsimages파일을 NameNode에있는 기존 fsimages파일과 바꿔치기하는 작업을 주기적으로 실행</u>하는 역할을하는 고마운 친구이다.

※fsimages파일을 저장하는 경로의값을 복수로 늘려서 여러군데에다 동시에 저장하게하는 방법도있다. 주로 2.x을쓰는 기업에서는 이런방식으로도 fsimages파일을 관리한다고 한다.

#### 각 버전별 HDFS특성

- 하둡 1.X : 블록기본크기 64MB. NameNode에 장애가 발생하였을떄 대비책이없다.
- 하둡 2.X : NameNode에 장애가 발생하였을때의 대비책이있다.
- 하둡 3.X : 기존파일의 2배의 용량으로 HDFS를 운영할수있는 기술도입. 이것을 **Erasure Coding**이라고하는데, 이것은 하둡 내부적으로 Raid를 구성하는것과 같다고 생각하면된다.

※Erasure Coding?

보통 2.x대에서는 100mb의 파일을저장하기위해 레플리카포함 300mb 내외의 저장공간이 필요했는데, 약 200mb 정도로 줄여줄수있는 알고리즘 방식이다. 디렉터리나 파일단위로 Erasuer Coding을 적용하고, 적용하지않고, 레플리카를 그대로 유지할수도있다.

주로 적용하지않는 파일들이나 디렉토리는 용량이 매우작은경우이고

적용하는 파일이나 디렉토리는 용량이 큰 경우이다.

  
### 하둡 유용한 커맨드

```bash
hdfs dfsadmin -report :hdfs의 각 노드들의 상태를 출력하며 hdfs의 전체 사용량과 각 노드의 상태를 확인할수있음.

hdfs dfsadmin -report -live : live한 data node포함 hadoop상태 레포트
hdfs dfsadmin -report -dead : 죽은 data node 레포트
hdfs fsck [하둡파일경로]-files -blocks -locations :저장한 파일이 어디어디에 분산저장되었는지 확인

hdfs dfs balancer : 서로다른 스펙의 데이터노드를 하나의 클러스터로 구성하게될때 노드간 디스크 크기가 다르거나 등의 문제로 전체 데이터의 밸런싱이 되지않는 문제가 생겼을때 해결하는 커맨드. (신규 데이터 노드를 추가하는 경우에도 발생할수가있다.)

#하둡파일에서 balancer설정 
#hdfs-site.xml

<property>
    <name>dfs.datanode.balance.max.concurrent.moves</name>
    <value>50</value>
</property>

<property>
    <name>dfs.datanode.balance.bandwidthPerSec</name>
    <value>104857600</value>    
</property>


```

#### 맵리듀스

이 친구는 HDFS에 저장된 데이터를 계산 및 처리하는 역할을한다.
하지만 아까 위에서도 말했듯이 일괄 질의 처리기고 이녀석은 RDBMS와 좀 다르다. RDBMS는 상대적으로 크기가 작고  **정형데이터** 를 처리하는데 특화되어있다는 강점을 가지고있다. 그러므로 특정 쿼리와 데이터를 변경하는데 적합하다 (상대적으로 크기가작은)

또한 분산처리되어있는 데이터를 다시한곳으로모아 통합처리를한다면, 데이터를 계산하거나 처리하는데 매우 많은 시간이 들고 비효율적이게된다.

그래서 맵리듀스는 각각의 노드에서 처리를한 결과를 통합하는것이다.

각각의 처리는 맵이하고 리듀스는 통합하여 결과를 반환한다. 그리고 그 리듀스의 출력값을 중앙에 넘겨주는 흐름이다.

하지만 시대는 '빅데이터'라는 단어가 생겨날만큼 데이터의 크기가 커졌다.
수집되는 데이터는 정형데이터가아니라 이미지, 동영상, 텍스트 등 비정형 데이터가 주를 이루면서 수집되고 이동되는 데이터의 크기가 늘어나버린것이다.

빅데이터: 1024TB는 1PB(페타 바이트)가 된다. 일반적인 빅데이터는 현재 페타 바이트 단위이다.

데이터의 단위 : 비트(yes or no) < 1바이트(알파벳1 숫자1) < 1킬로바이트kb(몇개의 문단) < 메가바이트mb(1분길이의 mp3노래) < 1기가바이트 (30분 길이의 HD영화) < 1테라바이트(195~200편의 FHD영화) < 1페타바이트pb 

※ 1024배씩 단위가 커진다. 1바이트는 1024비트, 1기가바이트는 1024메가바이트.

RDBMS와 맵리듀스의 차이를 표로 표현한다면

|구분|RDBMS|맵리듀스|
|:-----:|:-----:|:----:|
|데이터크기|기가바이트|페타바이트|
|접근방식|대화형과 일괄 처리방식|일괄 처리방식|
|변경|여러번 읽고 쓰기|한번 쓰고 여러번 읽기|
|트랜잭션|ACID(원자성,일관성,고립성,지속성)|없음|
|구조|쓰기 기준 스키마|읽기 기준 스키마|
|무결성|높음|낮음|
|확장성|비선형|선형|


맵리듀스는 크게 맵(매퍼) / 리듀스로 단계로 나눠져있다. 

각 단계는 입-출력 으로 나눠져있고 JSON파일형식으로 데이터를 처리한다.

맵 단계에서 입력,처리하여 출력한 값은 리듀스가 입력으로 건네받게되고, 리듀스는 사용자가 지정한 리듀스단계에서 수행해야할 일을하여 최종적으로 결과물을 출력하게된다.

그럼 어떤 단계에 어떤 작업을 맡기는게 좋을까?

맵 단계에서는 주로 **이상치** (결측값, 문제가있는 값이나 레코드 등)를 걸러주는 작업을 수행하는것이 적합하다.
이렇게 걸러진 JSON값들을 리듀스의 입력값으로 넘겨서 리듀스는 깨끗한 데이터세트에서 우리가원하는 값을 찾아 출력하게된다.

단, 맵 -> 리듀스 단계로 넘어가는 과정에서 JSON값들은 KEY를 기준으로 정렬되고 그룹화하게된다.

    EX) 

    #맵 출력
    

    (1950, 11)
    (1950, 12)
    (1950, 03)
    (1821, 01)
    (1822, 07)
    (1821, 05)

    #리듀스 입력
    #reduce (key, list(value))

    (1821, [01,05])
    (1822, [07])
    (1950, [11,12,03])



맵에서 리듀스로 넘어가는 단계에서 위와같은 작업이 이루어진다. 아까 말했던것처럼 KEY를 기준으로 정렬되고 그룹화하게되는것이다.

그렇다면 내가 만약 리듀스 단계에서 각 년도가 가지고있는 가장 마지막달을 구하는 함수를 작성하였다면, 리듀스 단계에서는 위와같이 입력받고 아래와같이 출력하게된다. 
    

    (1821, 05)
    (1822, 07)
    (1950, 12)


이제 맵리듀스가 뭘하는 친구인지 간단하게 알아보았다. 맵단계에서 입력할때, 어떤 데이터를 어떤 타입으로 넣을지는 사용자가 정할수있다.
각 행의 타입을 텍스트로 인식하는 텍스트 입력 포맷을 선택하면 텍스트이면서 키-값 의 형태를 가지게된다.

#### YARN

YARN은 하둡2.0부터생긴 **하둡클러스터 리소스 매니저**이다.
맵리듀스같이 분산처리 알고리즘, 시스템을 YARN 이라는 녀석위에서 작동시킬수있고, 맵리듀스뿐만아니라 **다른 분산처리 시스템**도 YARN에서 실행시킬수있다.

이말은 즉, YARN라는 친구는 하둡안에 원래 내장이되어있던 맵리듀스가 하둡 클러스터내부에있는 자원(HDFS파일 등)을 사용할수있게하는 중간 다리 같은 역할을하는것이다.

![YARN의위치](https://www.puzzledata.com/wp-content/uploads/2020/05/2-1-1.png)


이 YARN이라는 녀석은 하둡 2.X부터 나온친구이고, YARN을 사용하게 하둡을 설정하면 데몬에 **리소스매니저**라는 데몬이 하나 더 뜨게된다.

- 리소스 매니저 : 하둡 클러스터내부에 딱 1개. 하둡 클러스터 전체의 리소스(자원)을 관리하는 역할을한다. 클라이언트가 요청한 어플리케이션마다 자원을 관리.

- 노드 매니저 : 각 슬레이브 노드마다 1개씩있다. 컨테이너와 자원의 상태를 RM(리소스 매니저)에게 통지한다.

- 어플리케이션 마스터 : 각 어플리케이션마다 1개.어플리케이션의 실행을 관리하고 상태를 RM에 통지. 중요한건 <mark>어플리케이션 마스터 실행 요청이들어와야 실행된다. 평소에는 실행x </mark>

- 컨테이너 : 어플리케이션을 수행할수있는 역할을한다. 제한된 자원을 소유하고 제한된 자원만큼 컨테이너를 만들어 그 안에서 어플리케이션을 수행한다. 상태를 리소스매니저에게 통지.
  

그러니 이 YARN이라는 친구가 생김으로써 실행되는 데몬은 위와 같이 하둡 클러스터 내부에 하나있는 리소스매니저, 각 노드마다 하나씩있는 노드 매니저, 평소에는 동작하지않고 가만이있다가 RM에게서 작업 요청이들어오면 실행되는 어플리케이션 마스터 로 구성되어있다.


그러니까 유저가 어떤 어플리케이션을 만들어서 일을 제출하게되면(YARN에게 서브밋하게되면), <u>리소스 매니저가 전체 클러스터의 리소스 상태를 주기적을 보고 받고있다가 리소스 매니저가 어플리케이션 마스터(각 어플리케이션마다 한개있는것)을 어느 노드에서 실행시킬지 선출해서 선출된 노드매니저에게 명령을 내리게된다.</u>


그렇게 리소스 매니저에게 명령받은 해당 노드매니저의 노드는, 평소에 존재하지않고 가만이있던 어플리케이션 마스터를 (1.x버전으로친다면 잡트래커임, 일관리자) 구동시켜서 일을 처리한다.

YARN의 동작구조를 보면 아래와 같다.

![YARN아키텍쳐](https://techvidvan.com/tutorials/wp-content/uploads/sites/2/2020/03/apache-hadoop-yarn.jpg)

하둡2.X버전부터는 잡트래커나 태스크 트래커가 없어지고 YARN이 생기면서 위의 그림같이 **리소스매니저, 노드매니저, 어플리케이션마스터, 컨테이너** 등 새로운것들이 생겨났다.

또한 YARN같은 경우 위의 그림과 설명대로 1.X버전대보다 실행이 복잡하게 바뀌어서 작은 단위의 작업을 처리하는데 YARN을 이용하는것은 비효율적이다.

왜냐하면 YARN에게 어떠한 작업을 제출하게되면 이 제출된 작업을 실행하기위해서 자바에서 어떤 머신을 포크하고, 기타 등등 여러가지의 작업을 거쳐서 구동시키고 리소스 매니저가 노드매니저들에게 상태를 보고받아 체크하고 일을 시킬 적절한 노드를 선출하고 또 어플리케이션 마스터를 구동하고,  등등의 많은 사전작업들을 하기 때문이다.

그렇기때문에 아주 간단한 작업을 제출한다고해도 20초 ~ 30초가 걸리는것이고 작은 데이터를 처리하기에는 적합하지않은것이다.

YARN을 조금 정리해보자면

-어플리케이션은 메모리의 최소할당과 최대할당에 대한 요청이 가능하다.
-기본적인 메모리 할당은 스케줄러에 지정되어있다.
-YARN에서는 진행상황과 상태정보를 어플리케이션마스터에게 보고
-클라이언트는 진행 상황의 변화를 확인하기위하여 매초마다 어플리케이션 마스터를 조회
-YARN에서 진행상황 모니터링은 리소스매니저의 웹UI를통해 실행중인 모든 어플리케이션을 확인할수있고, 각 링크가있는데 이것이 <makr>어플리케이션의 마스터의 웹UI로 연결된다.</mark>

어플리케이션 마스터의 웹 ui로 연결된다는 말은 곧 리소스매니저가 어느 노드의 노드매니저에게 일을 시킬지 우리는 모르므로 언제나 바뀔수있다.


#### 하둡의 주요 단어

-노드 : 하나의 컴퓨터. 하나의 서버. 즉 클러스터로 묶을수있는 구성원. 30~4-개의 노드가모여 하나의 rack을 이룬다.

-rack : 노드들이 모여 하나의 rack을 이룬다. rack은 물리적으로 같은 네트워크의 스위치에 모두 연결되어있다. 데이터의 이동할수있는 폭이 크기때문에 속도가 빠르다.

-하둡클러스터 : 여러개의 rack이 모여 하나의 하둡 클러스터를 구축하게된다.

-탐색 : 디스크상에서 탐색이라는것은 데이터를 읽거나 쓸 때 디스크의 헤더를 디스크의 특정위치로 이동시키는 조작이다. 디스크의 전송속도는 디스크의 대역폭과 관계가있다. 대역폭이 작을수록 데이터를 읽어오거나 작성하는데 시간이 줄어든다.

-B트리 : 관계형 데이터베이스에서 사용되는 자료구조이다. 탐색을 수행하는 속도에 제한이있다. 데이터베이스의 상당 부분을 변경할때 B-트리는 데이터베이스를 재구성하기위해 소트와 머지를 사용해야하므로 맵리듀스보다 비효율적이다. 이것이 빅데이터를 RDB에서 처리하는것이 비효율적인 이유이다.


-★블록의 지역성(Locality) : 맵리듀스같이 하둡내에서 어떤 일을 시킬때 작업에 필요한 정보를 가지고있는 블록만 일을하도록 NameNode나 JobTracker가 일을시킨다. 또한 해당 블록을 가지고있는 DataNode는 **네트워크를 통해 데이터를 전송하지않고** 일단, 로컬에있는 블록데이터를 가지고 연산을 실행한다. 이것을 블록의 지역성이라고부른다.

    ex) 기온정보를 담고있는 파일의 블록이 3개로 쪼개져있고 각각 DataNode 1,5,12번에 저장되어있다고 가정한다면, 맵리듀스를 통해 년도별 기온정보를 추출하는 코드를 작성했다면 기온정보 파일의 블록을 가지고있는 1,5,12번 DataNode만 로컬에 가지고있는 블록정보로 작업을 시작하는것.

## Spark

하둡에 저장된 자원,데이터들을 분석하고 조작하는 일종의 처리기다.
하이브랑 유사하게 하둡내부에있는 데이터를 sql로 배치로 사용할수있게 해주고 하이브에비해 속도도 굉장히 빠르다. 
spark가 빠른이유는 **메모리상에서 데이터를 처리하기때문이다.**
spark가 등장하게된 이유는 MR(맵리듀스)의 단점을 보완하려고 나온거였다. 덤으로 램 가격이 싸지면서 메모리상에서 처리할수있는것이 많아졌기때문에 메모리상에서 데이터를 처리할수있도록하여 MR보다 빠르다는 특징을 가지고 출시되었었다.

mr과 spark의 차이점을 간단하게 정리해보자면

    MR VS  Spark

    MR : INPUT이 HDFS에 읽고 >  HDFS에 쓰고 > HDFS에 읽고 > HDFS에 쓰고 를 반복한다. 그렇기때문에 DISK IO가 많이 발생한다.
    
    SPARK: 메모리상에서 데이터를 처리하기때문에 DISK IO가 발생할것을 메모리에서 처리해버린다. 뭔가를 처리할때마다 매번 디스크에 접근해서 읽고/쓰고 를 반복하지않는다는말이다. 읽어와서 메모리에 저장하고있다가 필요할때 불러왔던 결과를 메모리에서 불러다준다. 단, 메모리기반이기때문에 접속장애에 취약하다. 실행되고있을때는 이미 메모리에 임시로 저장해놨기때문에 괜찮지만, 따로 저장하지않은상태에서 접속이 끊기거나하면 연산했던 결과는 사라진다

    또한 같은 4테라의 파일을 정렬처리할때 시간이 약 3배정도 절약되는걸 확인할수있다. (2004년기준)

다만, 단점이있는데 메모리상에서 데이터를 처리하기때문에 <u>전체 클러스터의 메모리 사이즈에서 벗어날만큼 큰 데이터의 처리는 할수없다는것이다.</u>  보통은 메모리보다 디스크가 더 크기때문에, 스파크에서 처리하지못한 데이터는 하이브에서 처리할수있다.
<u>(하이브는 디스크단위로 읽고쓰기때문에)</u>


그럼 Spark의 구조는 어떨까?

크게 RDD와 DataFrame 으로 구분되는데 리스트형식으로 RDD를 구성하고 RDD를 DF로 만들기위해 차원으로 구성하면 DF가 만들어진다.

### RDD 자세히 알아보자.

RDD는 SPARK의 가장 기본개념이자 코어 개념이며 사상이기도하다.
지금은 SPARK가 많이 보완되고 발전함으로써 거의 모든것을 데이터 프레임으로 처리할수있지만, 초창기의 SPARK는 데이터프레임이 없었기때문에 RDD 프로그래밍으로 처리했다고한다

SPARK의 SQL이나 스트리밍,분석,데이터 프레임 등 모든 프로세싱들은 다 RDD기반이다.

그렇기때문에 RDD는 SPARK의 가장 기본이자 기초 개념이고 코어 개념이기때문에 알아두는것이좋다.

그럼 RDD는 무엇이고 어떤 구조로 이루어져있을까? 알아보자.

RDD는 <u>Resilient Distributed Datasets</u>의 약자로, 대충 <u>탄력적인 분산 데이터셋</u>, 컨테이너를 의미한다.

아래에서 다룰 예제에서 볼수있듯이, <u>s.split('\t'[2])</u> 라고 사용한 이유가 바로 <u>rdd는 스키마가 없기때문에 탭이나 일련의 기준으로 나눠준다음에, 나눠준 라인에서 우리가 원하는 값이 들어있는 위치를 직접 지정해줘야한다. [n]처럼 말이다.</u>

RDD Fault Toleranece : 작업중 장애가발생한 rdd의 변환단계에서 어떻게 리트라이를 할것인지에대한것. rdd는 바로 전 단계의 rdd 변환단계를 다시 실행한다.


예제

    ex) txt로된 log파일에서 error로 시작하는것들만 모아서 새로운 RDD생성

    messages = logtext.filter(lambda s: s.contains("ERROR")).map(lambda s : s.split('\t'[2]))

    #(※위는 RDD기반이라 lambda가 계속나오는것이고, 데이터프레임 사용시 logtext(데이터프레임이라는가정).filter(col("str").contains("ERROR")).collect()) 

    #위의 두 구문은 한줄의 라인, 데이터프레임의 한줄의 열에서 "ERROR"를 포함하는 내용을 모두 찾는다. (.contains가 해당 열이나 라인에서 매개변수로들어온 값과일치하는것을 찾아 반환.)
    이후 탭으로 다 스플릿을해서 두번째에존재하는 값을 메세지로 가져온다.

    #만약 error로 시작하는 라인을 찾고싶다면 .startswith('error')로 사용하면된다. 단 rdd.

    messages.cache()

    #캐시가되면 해당 서브밋(spark마스터 노드가 나눠준 task)을 처리하는 노드(워커가될수도있고 로컬이면 자기자신이되겠다.)의 메모리 영역에서 일부 영역을 캐시영역으로 활용한다. 
    재플린이나 그런걸쓰면 해결이되겠지만, 안쓴다면 해당 기능을쓰는게좋다. 왜냐하면 데이터프레임이든, RDD는 HDFS에서부터 파일을 불러오는것을 BASE RDD/ DATA FRAME이라고하고 그 RDD, DATA FRAME을 원하는 값을 얻어내기위해 보통 한번의 변환작업으로 끝나지않기때문에 계속 변환 RDD가 생겨난다.

    #RDD1= baserdd.filter(~~)
    #RDD2= RDD1.filter(~~~)

    #위와같은 작업모두 변환작업에 속한다. 이렇게 전단계나 전전단계에서 만들어낸 RDD를 계속 활용하기위해서 캐시에 저장해놓고 이미 불러오고 만들어냇던 결과들을 잠시 저장해놓고 쓰는게 작업 효율성이 당연히 좋아진다. 만약 캐시기능을 쓰지않는다면 SPARK는 HDFS부터 파일을 읽어오는 처음작업부터 다시시작하게된다.


    messages.filter(lambda s : "syntax" in s).count()

    #그렇게 error의 내용을 포함하고있는 내용만 rdd에서 (위에서는 error만 추출한 결과를 새로운 rdd로만들지않고 바로 덮어썼다.)
    syntax가 몇개나왔는지 갯수를세서 결과를 반환한다.


위의 예제에서도 볼수있듯이, RDD는 두가지 종류의 함수로나누어진다.

- Transformations(변환):filter, map,groupby,join 등
- Action : show,save,count 등 <u>실질적으로 동작하여 결과물을 드라이버에 리턴하거나 외,내부에 저장</u> 등을 수행하는것들.

위와 같이 나눠진 동작들중에서 SPARK가 실제로 동작을하는 시점은 <mark>Actions</mark> 시점이다.

### DATA FRAME

RDD를 구성하여 DATA FRAME을 구성할수있다. 데이터 프레임은 무엇인가? 간단한게 말하면 SQL의 테이블과 비슷하게생긴건데 더 정확하게는 <u>엑셀의 스프레드시트와 똑같이 생겼다</u>.
열과 행이있으므로, 스키마가 존재하는것이다. (스키마: 데이터의 구조를 정의해놓은 내부 구조, 뼈대, 틀 같은것)

데이터프레임이 스키마를 가지고있어서 조금더 관계형 DB같은 구조를 (정형화)가지고있기때문에, 데이터 프레임에서는 SPARK SQL을 사용할수있다.

하지만 SPARK의 데이터프레임은 어디까지나 RDD를 기반으로 만들어진것이기때문에, 우리가 흔히아는 <u>Pandas data frame</u>과 호환되지않는다. 또한 데이터 프레임을 구성하는 방식도 다르다.

### RDD VS DataFrame

RDD와 데이터프레임의 차이점과 서로 어떤면에서 강점을 가지고있는지 알아보자.


- RDD개발은 SPARK에서 로우레벨 인터페이스이다. 직접 데이터를 핸들링하는 로우레벨 인터페이스에 속한다. 스키마가 없기때문에, 데이터프레임이 스키마가있어서 2차원이라면 RDD는 1차원에속한다. 한줄,한줄 라인처럼 되어있는것.

- 데이터프레임은 스키마를 가지고있다. '분산되서 저장되고있는 스프레드시트' 정도로 이해할수있다. 즉 조금 더 관계형,정형에가까운 구조를 가지게된다.

- 데이터 프레임은 python이나 스칼라(spark의 개발언어)나 큰 성능의 차이는 없지만 RDD는 python과 스칼라의 성능차이가 꽤나 차이가난다.

- 데이터프레임은 스키마가 있기때문에 rdd보다 더욱 데이터를 직관적으로 알아보기쉽다.

#### SPARK STREAMING

스파크 스트리밍은 INPUT되는 데이터를 배치사이즈만큼 쪼개서 데이터를 처리하게되는 구조를 가지고있다.

여기서 배치사이즈는 사용자가 지정하는것이고, 실제로 데이터를 처리하는 과정은, 내부에 있는 <u>스파크 엔진 쪼개진 배치사이즈만큼 프로세싱을해서 데이터를 처리하게된다.</u>

여기서 INPUT데이터는 Kafka가될수도있고 HDFS/S3에서도 가져올수있고, 트위터 등 다양한곳에서 가져올수있다.

이름은 스파크 스트리밍이지만 실시간으로 처리하는구조는아니고 내가 지정한 배치사이즈만큼 인풋데이터를 쪼개서 스파크 엔진이 사이즈만큼 처리하는것이기때문에, 어떻게보면 몇초간격으로 데이터를 처리할것이냐 같은 느낌에 가깝다.

예를들어 0~4초의 시간이있다면 이 시간동안에 각각의 DStream을 생성하게되고, 각각 Dstream별로 스파크 연산을 적용하게하는 아키텍쳐를 가지고있다.

![spark_streaming_architecture](./spark/스파크스트리밍.PNG)

## Zookeeper

주키퍼는 하둡 에코시스템을 관리하거나 분산시스템을 관리하는 **분산코디네이터**라고 보면된다.

주키퍼 서비스는 복수의 서버에 복제되며, 모든 서버는 데이터 카피본을 저장한다.

주키퍼는 보통 n개의 서버로 단일 클러스터를 구성하고 이렇게 구성한것을 서버 앙상블이라고하는데 주로 **홀수**단위로 구성을한다.

zookeeper를 설치하고 실행시켜보면 먼저살아나는 순서대로 리더와 팔로워가 나누어진다. 언제나 리더와 팔로워가 바뀔수있는것이다.

팔로워 서버들은 클라이언트로부터 받은 모든 업데이트 이벤트를 리더에게 전달한다. 또한 클라이언트는 모든 주키퍼 서버에서 읽을수있으며, 리더를 통해 쓸수있고 과반수 서버의 승인이 필요하다.

여기서 중요한건 <u>과반수</u>이다.이 주키퍼를 홀수로 구성하는이유는 주키퍼는 살아있는 서버가 과반수이면 계속 서비스를 유지할수있는 특성을 가졌기때문이다.


주키퍼는 분산 베타적 잠금이라고해서 이것은 DB의 락 시스템을 생각하면 어렵지않을것이다.
서로다른 어플리케이션이 데이터를 쓰거나 변경하려고하면, 먼저 쓰거나 변경을하고있는 어플리케이션의 작업이 끝날때까지 아무도 데이터를 읽거나 쓸수없는것이다.


주키퍼 내부에는 **z노드라는** 녀석이있다.

그럼 이 <u>z노드는</u> 무엇인가?

z node란 Zookeeper에서 데이터가 저장되는 단위로서, 데이터가 저장되는트리의 노드라고 생각할 수 있겠다.

총 세종류의 znode로 분류하는데 영속의 종류에따라 세 종류의 차이점이 생긴다.

1. Persistent Nodes(영구노드) : 명시적으로 삭제되기 전 까지 존재한다.
2. Ephemeral Nodes(임시 노드) : 세션이 유지되는동안 활성(세션이 종료되면 삭제된다.) 자식 노드를 가질수없다.
3. Sequenece Nodes(순차노드) : 경로의 끝에일정하게 증가하는 카운터가 추가된것. 영구 및 임시노드 모두에적용가능하다.
   

![트리형태의znode](https://www.oreilly.com/api/v2/epubs/9781784391324/files/graphics/1324OS_02_02.jpg)

위와같은 형태를 가진것이 znode인데 간단하게 설명하자면 

- '/' 처럼 절대경로로 구분된다.
- 변경이 발생하면 버전 번호가 증가한다.
- 데이터는 항상 전체를 읽고쓴다
- znode는 1m이하의 데이터를 가질수 있으며 자식노드를 가질수있음

ZooKeeper는 여러 서버에 분산되어 있는 znode를 관리하기 위한 서비스이다. znode는 메모리에 저장되어 빠른 속도를 보장하지만, 크기에 제한을 갖는다. 그러므로, ZooKeeper는 여러 클러스터에 공유되어야 하는 설정 값이나 리소스 상태 정보등을 저장할 때 매우 유용하다.

znode에 분산관리가 필요한 서비스같은것들을 node형식으로 znode에 붙여서 그것을 주키퍼가 관리할수있도록 만드는것이 주키퍼의 역할이다.

znode에서 node를 삭제시키고 주키퍼에서 관리하길원하지않는다면 node를 삭제시킴으로써 주키퍼에서 탈퇴를할수있다. 반대로 등록은 가입이되는것이다.

## Kafka

카프카는 실시간 데이터 수집을 도와주는 프레임워크다.
저장방식은 HDFS와 비슷하게 지정한 갯수만큼의 복제본을 서로다른 노드에 저장하고, Kafka에서는 파티션이라는 개념이있다.

파티션의 개념과 토픽 레코드 등을 알기위해서는 카프카의 내부 구조를알아야한다.

-토픽: **데이터를 구분하기위해 사용하는단위.**한개이상의 파티션이 존재하고, 프로듀서로부터 받은 데이터를 보관하고있다. 프로듀서로부터 받은 오프셋, key,value(즉 실제값)들을 **레코드**라고 부른다.

-**파티션** :  토픽에 속한 레코드를 실제 저장소에 저장하는 가장 작은 단위라고 보면된다. 여러개의 브로커에 나눠서 파티션을 구분할수있다. 만약 내가 어떤 토픽을 생성하면서 그 토픽에 세개의 파티션을 할당했다고하자, 그러면 0부터 시작해서 파티션 0 , 1, 2 로 구성이되어서 각 브로커의 상태에 맞게 파티션별로 오프셋을 0부터 차례로쌓는다. 파티션이 여러개일때는 <u>라운드 로빈 방식으로 파티션별로 번갈아가면서 저장한다</u>

-레플리카: hdfs와 똑같이 복제본을 의미한다.

-브로커 : 메세지큐 시스템에는 메세지를 관리하거나 보관해주는 서버가 필요한데 Kafka에서는 이것을 **브로커**라고부른다.
<u>즉, 메세지를 저장하는 물리적 서버</u>

-오프셋 : 각 메세지의 저장위치를 뜻한다. 메세지를 식별할수있는 유니크한값인데 **0 부터 시작한다.**  어떠한 토픽을 저장하면, 이름은 <u>토픽이름-n</u> 이다. 여기서 n이 0부터 시작하는것이다.



![카프카의이해](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FcwkIif%2Fbtri435BnZb%2FrEDEnIRfzuzL6V7N197KOK%2Fimg.png)


컨슈머 : 메세지를 소비하는쪽. 이미 소비한 메세지는 다시 읽지않는다. 각 브로커가 관리하고있는 오프셋을 따라간다.

프로듀서 : 메세지를 보내는 녀석. 실시간으로 데이터를 수집해서 메세지형식으로 보내는 역할을하는 친구라고 생각하면된다.


## ELK Stack

### Elastic search

엘라스틱서치는 Nosql의 구조를 가지고있는 검색엔진 중 하나이다. 함께 사용할수있는 키바나, 로그스태시와 같이사용하게되면 대시보드나 시각화 모니터링등을 더욱 편리하게할수있으며 데이터의 수집도 편리하게할수있다. 즉 엘라스틱서치는 <u>JSON</u>포맷을 사용한다는것이다.

엘라스틱서치는 저장소로쓰일수도있고 분석기로 쓰일수도있고 여러가지로 활용 가능하다.

그럼 엘라스틱서치의 기본적인 구조를 알아보자.

엘라스틱서치의 시스템구조는 아래와 같이 되어있다.

- 클러스터 : 독립된 엘라스틱서치의 시스템환경. 1개이상의 노드가 모여서 이루어진것. 타 시스템, 프레임워크의 클러스터와 거의 동일한개념이다.

- 노드 : 실행중인 엘라스틱서치의 시스템 프로세스. 클러스터의 구성이된다. 하나의 물리적인 서버에서 여러개의 노드도 실행가능하다는점이 조금 특이한점이다. <u>노드들간에는 tcp port를 통해 서로 통신한다.</u>

- 도큐먼트 : 저장된 단일 데이터 단위. 이녀석이 가장 최소의 단위이다.

- 필드 : 도큐먼트안에 들어있는 실질적 값. {"name": "myname"} 이것은 필드이다. 

- 인덱스 : 도큐먼트의 논리적 집합. 1개 이상의 '샤드'로 구성되어있다. <u>RDB의 테이블</u>

- 샤드 : 색인 & 검색을 진행하는 작업단위이다. 프라이머리 샤드(원본) / 레플레카 로 나뉜다. 샤드의 저장구조는 Kafka에 파티션개념과 비슷하다. 프라이머리 샤드와 복제본은 반드시 서로 다른 노드에 저장된다. 또한 프라이머리 샤드도 같은 노드에 연속되게 저장되지않는다. (ex) node-1:프라이머리 0,2 | node-2:프라이머리1,3..)

![엘라스틱서치 시스템구조](./elk/엘라스틱서치.PNG)

위의 그림을보면 더욱 이해가쉽다.


기본적으로 엘라스틱서치 시스템은 위와같은 구조를 가지고있으며 사실 이름이 생소해서그렇지 인덱스, 샤드, 도큐먼트가 RDB의 어떤 기능과 일치하는지만 이해하면 크게 어렵지않다.

문법은 PUT, GET, POST 등 HTTP 요청을 통해 이루어진다.

여기서 알아아할점이있는데, 인덱스(테이블같은개념)을 생성할때 각 인덱스별로 프라이머리 샤드와 복제본 세트 수를 설정할수있다.

또한 멀티 테넌시 기능을 지원한다.

멀티테넌시는 서로다른 인덱스를 묶어서한번에 검색하는 기능이다.

    get books,foods/_search 


엘라스틱 서치에는 <u>매핑</u>이라는 기능도있는데,
해당 기능은 엘라스틱 서치의 특정 인덱스의 구조를 미리 정의하는 작업으로, 굉장히 중요한 작업이다.


매핑작업을 하지않는다고해서 엘라스틱서치에 데이터를 적재할수없는것은아니다. 하지만, 매핑작업을하지않은 인덱스에 데이터를 밀어넣게되면 엘라스틱 서치는 들어오는 데이터의 구조에따라 임의로 타입을 지정하게된다.

이 말은, <u>들어간 데이터가 내가 원하지않는 데이터의 타입을 가질수있게된다는것.</u>이다.

데이터의 타입은 무척이나 중요하고 추후에 다룰 키바나 또한 데이터타입에 따라 시각화한 자료가 다르게 나올수있기때문에 반드시 매핑작업을 사전에하는것을 추천한다.


**매핑작업 = RDB의 스키마정의** 라고 이해해도된다.

단, 매핑작업을할때 필드를 추가하는것은되지만 (중복되지않게), 이미 만들어진 필드를 삭제하거나 필드 타입 및 설정을 변경하는것은 **불가능**하다. 즉, 이미 매핑된 인덱스의 구조를 바꾸는것은 안된다는것이다. 

그럼 이미 매핑을해버렸는데 인덱스의 구조를 바꾸고싶을땐 어떻게해야할까?

어쩔수없이 해당 인덱스의 구조를 복사해서 원하는대로 구조를바꾼 후,**인덱스를 재생성**해야한다. 또한 **재색인**작업도 해줘야한다.

-색인:데이터를 검색될 수 있는 구조로 변경하기 위해 원본 문서를 검색어 토큰들로 변환하여 저장하는 일련의 과정

### Kibana

엘라스틱서치에 적재된 데이터를 기반으로 주로 시각화를 하여 데이터 마켓을 구축하는 등, 엘라스틱 서치에 최적화된 <u>시각화 툴</u> 이다.

또한 엘라스틱서치 내부에있는 데이터를 실시간으로 가져오는 모니터링 기능도 탑재하고있다.

키바나를 설치하고 실행한다고해서 바로 알아서 엘라스틱서치의 데이터를 가져오는것은 아니다. 

키바나를 켜고, 좌측 메뉴 최하단의 대시보드의 스택 매니지먼트를 클릭하면, 좌측의 메뉴가 새로바뀌며 '키바나'라는 항목이 아래에있다.
그곳의 <u>create indexpattern</u> 를 눌러줘서 <u>인덱스 패턴을 생성해줘야 엘라스틱서치의 데이터로 대시보드나, 시각화를 할수있다</u>

### Logstash

로그스태시는 ELK 스택에서 데이터의 수집을 담당하는 일종의 '수집기' 이다.

이 ELK 스택안에는 사실 Beats라는 친구도있는데, 이 친구는 데이터를 수집을하되, 데이터를 가공하는기능은 전혀없기때문에 빠르고 가볍게 데이터를 수집하는데 의의를둔다.

하지만 로그스태시는 Beats와 다르게, 데이터를 수집하는 동시에 데이터의 가공도된다. SPARK나 하둡의 맵리듀스처럼 엄청나게 큰 데이터와 엄청나게많은 가공을할수있는것은 아니고, 데이터 가공에있어서 조금 제한적이다.

로그스태시의 조금 더 정확한 기능은 <u>데이터 파이프라인 구축</u>이다.

로그스태시는 카프카나 메세지큐(레빗mq,redis 등등), 인터넷, db,lot.. 어디서든 데이터를 수집해와서 어디로든 보낼수있다.

로그스태시의 구조, 문법은 아래와같이

>INPUT > FILTER > OUTPUT 으로 이루어져있다.


인풋이 수집, 필터가 가공, 아웃풋이 가공한 데이터를 어디로 보내고 적재할것인가를 설정해주는 부분이다.

로그스태시는 name.conf 파일이라고해서 .conf 파일 포맷으로 파일을 만들어야하는데, 로그스태시의를 작동하기위해 코드를짤때도

    input
    {

    }


    filter{

    }

    output
    {

    }


위와 같이 세 단계의 구조로 이루어져있다. 여기서 filter는 생략해도되지만, 가공이 필요하다면 엘라스틱서치에서 지원하는 여러 필터기능을 이용해서 input에서 수집해온 데이터를 가공하여 output으로 처리할수있다.


## Django

장고는 웹 프레임워크이다. PYTHON기반이고 경량의 웹 어플리케이션을 만들때 많이들 사용한다.
장고의 가장 큰 강점은 **MVC,MVT** 구조라는것이다.

장고의 핵심인 MVC 구조에대해 알아보자.


### Django의 구조

MVT? MVC? 조금 생소할수도있겠지만 결론적으로말하자면 **MVC==MVT**이다. 그저 약자의 차이일뿐이고 개념은 같다.

약자를 하나하나 살펴보면,

- MODEL : 안전하게 데이터를 저장. 유저들이 발생시킨 데이터나 우리(개발자)가 DB서버에 반영시키거나 추가,변경한 데이터들을 전송, 관리등을 하는 역할을한다. 

- VIEW : 데이터를 적절하게 유저에게 보여준다. 모델에있는데이터를 들고와서 유저가 원하는 형태로 만들어서 보여준다. 이부분은 우리가 직접 개발하여 어떤 데이터를 어떻게 보여줄것인가를 만들수있다.VIEWS.PY파일안에서.

- CONTROL/TEMPLATE : 사용자의 입력과 이벤트에 반응하여 모델과 VIEW를 업데이트한다. 


즉 MVC는 옛날의 웹 페이지같이 하나의 파일에 여러가지 기능들이 다 들어가있어서 섞여있는 구조였다면, MVC는 디자인/동작(컨트롤)/데이터 이러한 부분들을 각각 분리시켜서 작동하게하는 구조를 만든것이다.

이러한 구조의 장점은 개발자가 디자인을 수정한다고해서 이미 만들어놓은 동작이나 데이터구조에 영향이가지않는다. 

물론 디자인수정을 잘못해서 디자인이 깨져보이거나, 경로 설정을 잘못해서 페이지를 못읽어오는 경우도있겠지만, 동작이나 데이터부분의 코드를 직접적으로 잘못건드리는일이 없을것이다.


그렇게 모델 ,뷰 , 컨트롤러, 클라이언트(유저)가 유기적인 관계를 유지하며 동작하는것이 MVC패턴이고 대부분의 프로그램의 코드를 대분류로나눠서 관리하는것이 MVC패턴 의의이다.

MVC 패턴을 적용한 웹 프레임워크가 **Django**인것이다.
다만 Django에서는 Controler라는 단어대신 Template이라는 단어를 쓸 뿐이다.


Django의 구조를 알아보았으니 Dajango가 어떻게 MVT구조로 작동하는지 알아보자.

![장고의동작구조](./Django_gcp/Django동작구조.PNG)


위와같이 Django의 구조는 MVT구조라고 위에서 설명했다.
그 설명을 토대로 그림을 보며 자세한 설명을 덧붙이자면,

    -웹 브라우저에서는 여러가지 액션이일어나게된다.

    #WEB BROWSER에서 클라이언트나, 누군가가 URL을 클릭하게되는등, 정보를 입력하던(이미지 파일 업로드나 회원가입을위한 정보등)

    -웹 브라우저에서 일어난 액션은 장고서버로 들어오게되고, 사진의 URL DISPATCHER라는 부분이 요청된 URL 및 액션에대하여 분석을 진행하게된다.

    #액션은 꼭 URL이아니여도 여러가지가 될수있다.

    -분석한 URL에해당하거나, 클라이언트의 요청에 일치하는 VIEW로 요청을 또 전달하게된다.

    -VIEW는 사용자요청을받아서 데이터베이스에서 어떤 정보를 가져와야할지 모델에게 보낸다.

    #여기까지의 작업이 웹 브라우저>URL DISPATCHER > VIEW > MODEL 까지의 흐름으로 작업이 이루어진다고볼수있다.

    -그렇게 VIEW에게서 어떤 데이터를가져오라는 요청을받은 모델은 장고와 연결된 '실제데이터베이스'에서 통신을 주고받으며 필요한 데이터를가져와서 다시 VIEW에게 돌려준다.

    -모델을통해 실제 데이터베이스에서 가져온 데이터를 VEIW가 돌려받았기때문에 그것을 'Template'이 자바스크립트나 HTML등, 우리가 만들어놓은 홈페이지를 통해 웹브라우저가 원했던 정보를 보여주게된다.

    #기본적인 장고의 흐름은 위와같이 동작되지만 이 모든 작업은 각 영역을 분리하기위해 이렇게 동작되는것이다.


### Django의 미들웨어

Django가 어떻게 동작하는지 알아봤으면, Django 프로젝트를 생성하면 기본적으로 같이 사용할수있는 미들웨어, .py파일들에대해 알아보자.

- WSGI(wsgi.py) : 웹서버 게이트웨이 인터페이스의 약자. 브라우저,클라이언트의 요청이 웹서버 소프트웨어들를 거쳐 가장 먼저 wsgi에 들어오게된다. **웹서버**와**장고**를 적절하게 결합시켜주는 역할을한다.
- SETTING(settins.py) : **전체 프로젝트를 관리하는 설정파일**이다.
- URL RESOULOTION(urls.py) : wsgi를 거쳐 다음으로 요청을 처리하는부분. 주로 요청된 url에 따라 (urls.py는 정규표현식으로 url와 view를 연결시켜놓음) 연결된 view로 요청을 넘겨준다.
- VIEW(views.py) : 요청받은 요구에따라 데이터를 반환할지, 데이터를 가져올지 실질적으로 결정하는 부분. 모델.py에서 가져온 데이터를 가공한다. 따지자면 백엔드에 속하는 기능들을 주로 작성함.
- MODEL(models.py) : 장고와 연결된 데이터베이스에서 데이터를 가져오는 클래스로된 모델객체를 작성하는 부분이다.
- FORM(forms.py) : html을 통해 다양한 기능을 구현하면서 form을 생성해야할때 forms.py를 이용하면 쉽게 폼 객체들을 이용할수있다. 템플릿과 뷰를통해 충분히 폼을 구현할수있지만, forms.py에서 관리하게된다면 코드가 조금 더 깔끔해지고 편리해진다는 장점이있다. 모델에서 불러온 데이터들을 바로 불러다가 쓸수도있고 저장할수도있다.
- TEMPLATE(ex_name.html) : 웹서버 > wsgi > urls > veiw > model > managers > db 를 거쳐서 가져온 데이터를 다시 view가 돌려받아 가공하면 그것을 template이 가져다가쓰는것이다. .html파일로 여러기능을 구현할수있기때문에 실직적으로 동작의 마지막단계이자 **표현**에 속한다. 

위의 미들웨어 밖에있는것들

- Managers : 모델.py에서 클래스로 모델을 객체를 선언하기만하면 Managers라는 이 친구가 모델.py와 데이터베이스 사이에서 일을하며 데이터 베이스에서 모델에 선언된 모델객체의 구조에맞는 데이터를 꺼내 모델.py에게 돌려준다.  즉, 데이터베이스에 날리는 SQL쿼리문을 담당하는 녀석이다.
- Webserver : wsgi와 유저사이에 존재하며 클라이언트,브라우저를 통해 들어온 요청을 wsgi에게 보내고, 반대로 요청받은 작업을 wsgi가 클라이언트,브라우저에게 되돌려줄때도 wsgi대신 웹서버가 받아서 결과를 반환해준다. 이 부분은 밑에서 설명할 Nginx나 Gunicon등 서버소프트웨어가올수있다.

그외

{% csrf_token %}

    <u>폼 태그로 데이터를 전송할때 필수로 csrf_token을 요구한다.</u> csrf는 cross-site request forgery의 약자로, 정처기 준비해본사람이라면 이것이 사이트 간 위조 요청 공격기법이라는것을 알수있을것이다.

    csrf_token는 이 공격을 막기위해 보안적인 차원에서 폼에 해당 토큰을 필수적으로 요구한다.

    csrf_toekn의 작동원리는 서버는 클라이언트의 세션에 무작위 난수를 저장하고, 이후 클라이언트가 csrf_token 코드를 포함한 모든 리퀘스트에대해 서버에 저장된 난수 값과 클라이언트 세션에 저장된 난수값이 동일한지 확인한다.

    그래서 위조된 페이지는 서버가 발행한 무작위 난수 토큰값과 일치하지않을것임으로, 접근을 막아버리는 방식이다.

    이러한 보안토큰방식을 회피하고 탈취해서 사이트위조를 하려면 할수있지만, 그렇게하기위해서는 매우 까다로운 기술이 필요하다.

    즉, 정리하자면 서버가 클라이언트에게 난수 id를 발행시켜 관리하고있다가 해당 클라이언트의 요청이 위조된 요청이아닌지 id를 대조시켜보는것 정도로 이해할수있다.


### 프로젝트와 App

Django 프로젝트를 처음 만들면 프로젝트폴더와 APP폴더로 나누어져있다.

처음엔 프로젝트와 앱이 왜 나눠져있지?하고 생소할수도있다.

둘의 차이점과 하는 역할을 알아보자.

**프로젝트** : 하나의 웹 사이트를 구성하는 파일들이 모두 한곳에들어있는 폴더이다. 쉽게 말하면 하나의 웹사이트를 이루는 폴더.

App : APP은 의미있는 어떤 하나의 기능들을 뜻한다. 웹 사이트안에는 여러가지의 기능을 당연히 포함하고있을것이기때문에, <u>프로젝트안에는 다수의 app(기능)을 생성할수있다.</u>

### Settings.py

django의 환경 설정파일의 주요 요소를 살펴보자.

- DEBUG : TRUE모드이면 자세한 에러나 변수들의 다양한상태들으 볼수있다. 하지만 실제로 서버를 배포할때는 FALSE모드로 해놓아야지 이용자에게 디버그 정보를 유출시키지않을수있다.
- INSTALLED_APPS : pip로 설치한 app또는 본인이만든 app을 사용하기위해 추가해줘야한다. 즉 아까 위에서 설명한 app을 장고의 다른프로젝트의 하위 기능으로 똑딱 떼서 붙여넣을수있다는소리이다.한번만들어놓은 유용한기능을 재활용하는데 아주 유용하다. <u>내가만든것뿐만아니라 pip, 다른 사용자가만든 app을 가져다쓸수도있다.</u>
- MIDDELWARE_CLASSE : 리퀘스트와 리스폰스 사이의 주요 기능레이어이다. 주로 인증과 보안에관련된 내용들이 우리(개발자)는 모르지만 미들웨어부분에서 다양하게 처리하고있다.
- TEMPLATES : 장고 템플릿 관련설정, 실제 뷰(html,변수) 템플릿과 관련된 변수들의 컨텍스트과 탬플릿들을 검색하기위한 다양한 기능들을 다루는 파일.
- DATABASES : 데이터베이스 엔진의 연결 설정.
- STATIC_URL : 정적 파일의 URL(css,javascript,image,etc..),디렉토리의 위치나 찾는방식 기본경로 등 을 설정한다.


### Manage.py

프로젝트 관리를 위해 명령어를 제공하는 모음 파일이라고 이해할수있다.

주요 명령어로는 

- start [app] : 프로젝트에 앱생성 app부분은 만들고자하는 app 이름
- runserver : 테스트를위한 테스트 서버실행
- createsuperuser : 관리자 생성
- makemigrations [app] : app모델의 변경사항 체크(중요!)
- migrate : makemigrations 명령으로 체크된 변동사항을 실제로 DB에 반영.
- shell : 쉘을 통해 데이터를 확인한다.
- collectstatic : app마다 존재하는 static 파일을 한곳에 모은다.
  
<u>단, runserver 명령어로 실제 서버를 배포하면안된다.</u>

왜 runserver로 구동시키면안되느냐?

runserver로 서버를 잠깐 띄우는것은 장고에서 테스트를해보라는 의미로 제공하는 **테스트용 서버**이기때문에 실제로 프로젝트를 

배포하는데있어서 보안문제나 서버의문제나 여러가지 문제가많이 발생함으로써 <u>실제서버로 사용하기에는 부적합하다.</u>

## Nginx 

Nginx는 서버 소프트웨어이다. <u>서버 <-> Nginx <-> 클라이언트</u> 구조로, 클라이언트에서 받은 요청을 처리해주는 서버 소프트웨어라고 간단하게 볼수있다.

##  통계

DA만큼은아니지만, 통계또한 어느정도 알아두는것이좋아서 아주 간단한것만 정리해본다.

아래의 **ANOVA**를 이해하기 위해서는 몇가지 알아야할것이있다.
통계 왕초보라면(나) 모든 단어가 생소하게들릴것이다. 모집단과 표본은 쉬운개념에속하지만 ANOVA는 매우 생소할것이다.


**ANOVA**란?

쉽게 말해 분산분석을 의미한다. ANOVA = 분산분석. 

주로 두개이상의 집단들의 평균간 차이에 대한 통계적 유의성을 검정한다. 
집단평균들간 분산이 클수록, 집단 내 분산이 작을수록 평균의 차이가 분명해져서 분산분석이다. 두개 이상의 집단 평균들간 분산으로 비교하는것이기때문에.

- 사후검정 : 분산분석 후 어떤 집단이 유의미한 차이를가지고있는지 확인한다.
- 사후검정-귀무가설 : 집단들 사이의 평균은 같음
- 사후검정-대립가설 : 집단들 사이의 평균은 다름. (다르니까 대립한다 라고 암기해도 괜찮다.)

그럼 독립변수와 종속변수가 무엇인가?

- 독립변수 : <u>다른변수에 영향을받지않는다는 뜻</u>을 가진 변수이다. 말 그대로 통계분석이나 실험을계획할때 독립변수로 분류된 변수들은 다른 변수에 영향을받지않는 변수이다. 어디까지나 <u>영향을 받지않는다</u>이고, **종속변수에 영향을준다.** 이러한 독립변수는 연구자(우리)가 의도적으로 변화시킬수있다. 즉, <u>입력변수,x</u>

- 종속변수 : 다른말로 해석하면 의존적 변수이다. **독립변수에 영향을 받아서 변화하는 변수를 종속변수** 라고한다. 이 말은 결국 종속변수는 연구자(우리)가 독립변수의 변화에 따라 어떻게 변화하는지 알고싶어하는 변수라고 말할수도있다. 즉, <u>출력변수,y</u>


설명대로라면 독립변수와 종속변수는 <u>원인과 결과</u>의 관계를 가지게된다. 독립변수의 영향(원인) 을 받아서 종속변수가 변화(결과)하기 때문이다.

독립,종속 변수는 <u>범주형,연속형</u>모두 올수있다.

- 공변량 : 독립변수가 연속형 자료일때를 공변량이라고부른다.
- 요인 : 독립변수가 범주형 자료일때
- 연속형 자료 : 몸무게, 키 성적 등등
- 범주형 자료 : 지역, 성별, 학력 등등


### one way anova

집단의 평균들의 분산을 비교하는것인데 <u>오직 하나의 독립변수 또는 오직 하나의 요인을 고려할때만 해당</u> 한다.

가지고있는 데이터에대한 여러 상호배제적인 이론들에 대해서 평가하는것이 목적이다.

3개 이상의 그룹들을 비교하여 이 그룹들 사이의 차이가있는지 없는지 판별하는것이다. 각 그룹내에서 3개 또는 그 이상의 관찰값이 있어야함.

ONE WAY ANOVA를 통한 통계분석의 좋은예로는 
우리가 분석하려고하는 모집단이 펭귄이라면, 펭귄은 털갈이 시즌에 몸무게의 유의미한 변화가있는가? 를 알고싶어할수도있다.

그렇다면 이 가설에서 **독립변수=털갈이시즌** 이고, 분산분석에서 독립 변수들은 카테고리 그룹 내에서 조직되어야하므로 3월,4월,5월,6월 4개의 월별 분석이 진행되어야한다. 즉 <u>4개의 그룹이 분석에 사용된다.</u>

one way anova는 3개 또는 3개이상의 카테고리 그룹을 비교하여 이 그룹들 사이의 차이가있는지 없는지 판별하고 각 그룹내에서 3개 또는 그 이상의 관찰값이 있어야한다.

여기서 가설은 anova의 가설과 똑같이 **귀무가설**과 **대립가설**이있다.

### two way anova

two way anova는

one way anvoa와 비슷하지만 **독립변수가 한개 더 늘어났다.**
라고 생각할수있다. 

위의 펭귄의 예제를 two way에 적용시켜본다면, 펭귄은 털갈이시즌에 몸무게에 유의미한 변화를 보이는가? 에서 성별이라는 요인을 추가시킬수있다.

그러니 two way anova는 <u>펭귄은 털갈이 시즌에, 성별에따라 몸무게의 변화를보이는가?</u> 가 되는것이다.

그러면 요인은 시즌, 성별 두개가 되는것이고
**two way anova는 두개의 요인을 효과적으로 분석하는것이다.**

그러면 우리는 여기서 출력변수, 즉 종속변수에 영향을 주는지, 안주는지를 분석할수있다.


### manova

<u>다변량 분산분석</u>이다.

위의 아노바(anova,one,two way anvoa등)이 주로 독립변수 즉 입력변수의 갯수나 입력변수에따라 나뉘었다면 <u>manova는 출력변수, 즉 종속변수 중심이다. 종속변수가 2개 이상일때, 집단 평균의 **벡터**를 비교하는데 사용한다.</u>

그럼 왜 manova를 사용해야하는가? 어떨때 이걸 사용하지?

첫번째로 **종속변수들이 서로 상관이 높은경우 사용한다.** 왜냐하면 첫번째 케이스같은경우 단일변량에서 밝히기힘든 결합차이를 밝힐수있기때문이다.

첫번째 케이스는 예를들면 이러한 경우이다. 

    가계의 소득과 지출, 자동차의 휘발유 소모량과 배기량

두번째, 아노바(anvoa)를 반복해서 사용하면 1종 오류의 확률이높아진다. 즉 이말은 <u>실제로는 유의미한 차이가없는데 차이가있는것으로 결론내릴수있다는 의미이다.</u>

또한 anvoa를 많이 반복하게되면 1종 오류를 높이는 결과를 초래하기때문에 manova를 사용하는것이 적절하다.

만약 다섯번 사용하면 1종 오류의 확률은
>1-(.95)^(5)=23%

위의 확률 만큼 1종오류를 발생시킬 확률이 높아진다.


    1종오류?

    귀무가설(HO)가 실제로 참(True)여서 채택해야하는데 표본의 오차때문에 채택하지않는 오류는 말한다. 보통 알파 로 표기하고 유의수준이라고 부르기도한다.


    2종오류?

    1종오류와 반대로 귀무가설이 거짓이라서(False) 채택하지말하야하는데 표본의 오차때문에 이를 채택하는 오류이다. 보통은 베타라고 표기한다.

### one way anova / two way anova / manova 차이점


1. one way anova
2. 
   -3개 또는 그이상의 그룹에 대한 데이터를 비교하고 검정한다.

   -입력의 변수가 1개이다.

   -출력변수에대한 하나의 입력변수의 3개 또는 그 이상의 그룹의 평균들이 비교대상이다.

   -샘플의 그룹수는 3개 또는 그 이상이다.


2. two way anova

    -2개의 입력변수가 고려된 상태에서 3개이상의 그룹에대한 데이터를 비교하는 검정이다.
    
    -입력변수가 2개이다

    -출력변수에 대한 2개의 입력변수의 여러그룹에 대한 효과와 서로간의 효과가 비교대상이다.

    -샘플의 그룹수로 각변수는 여러 샘플을 가져야한다.


3. manova
   
   -출력변수(종속변수)간의 상관관계가 높은경우 사용한다.
   
   -출력변수(종속변수)가 2개이상일때 사용한다.

### 모집단 & 표본

모집단과 표본은 거의 세트라고 할만큼 뗄레야 뗄수없는 관계에있다.

- 모집단 : 연구자가 연구하고자하는 집단. ex) 대한민국 남자 여자의 키의 평균을 알고싶다면, 모집단은 대한민국의 모든 남자,여자의 키 가 된다. 

- 표본 : 모집단의 분포가 어떻되는지, 모집단이 어떻게 생겼는지 완벽하게 파악할수없기때문에, 모집단에대한 **표본**을 측정 또는 관찰해서 연구자가 알고하자는 모집단을 추정하는것.

- 상관관계 : 두 변수간의 직선관계를 의미하는데, 간단한 예를들어본다면 x가 작은 값을 가질때 y도 점점 작은값을 가진다면, <u>x와 y는 양의 상관관계를 가진다.</u>라고 표현한다. 반대로, x가 큰값을 가질수록 y가 작은값을 가지거나, 그 반대인 경우 <u>음의 상관관계를 가진다</u>라고 말한다.

- 상관계수 : 상관관계의 힘과 방향을 의미한다. -1에서 1까지의 값을 가질수있다. 어떤 상관관계에대한 상관계수가 0이라면, x와y는 아무런 관계가없다. -1이면 음의 상관관계를 가진다. 1이면 양의 상관관계.


## DB & SQL 

DB와 SQL에 대하여 알고있는것을 막상 표현하려고하니까 어려워서 면접에서 제대로 대답을 못하였다.
알고있는지식을 말로 표현하지못한다면,알고있지않는것이된다고했던가...맞는말이다.

그러한 실수를 방지하기위해 면접에서들었던 질문과 내가알고있었던것을 정리하고자한다.


### 실행계획

SQL을 실행하여 데이터를 추출하려고할때 **옵티마이저가 수립하는 작업 절차**. 주로 SQL튜닝업무를 하다보면  DBMS툴을 활용하여 실행 계획을 확인한다. SQL을 실행한 후 실행 계획을 판단하여 이 SQL이 어떻게 동작하는지 확인하는것.

실행계획의 분석을 위해 SCAN(스캔)을 알고있어야하는데, 데이터를 읽는작업을 의미한다. 스캔의 수행 방식을 **접근경로**라고 하고,
대표적으로 3가지의 방법이있다.

- FULL TABLE SCAN : 테이블 전체 데이터를 읽어 조건에 맞는 데이터를 추출하는방식
- ROWID SCAN : ROWID를 기준으로 데이터를 추출하며 단일 행에 접근하는 방식중에서 가장 빠르다.
- INDEX SCAN : 인덱스를 활용하여 원하는 데이터를 추출하는방식.

가장 쉬운 접근방식은 풀과 인덱스 스캔이다. 이 중 테이블에 데이터가 많지않아서 인덱스를 타야하는 시간소요가 불필요하다고 느껴지는 테이블에서, 추출해야하는 데이터 양이 엄청 많다면 풀 스캔이 유리하고,  <u>반대로 많은 데이터가 있는 테이블에서 내가 원하는 데이터를 추출하기위해서는 인덱스 스캔을 사용하는것이 유리하다.</u>

그럼 rowid 스캔을 사용하는경우는 어떤 경우일까?

- 조건절에 rowid를 직접 명시할경우
- index 스캔을 통해 rowid를 추출한 후 테이블에 접근할 경우.

**rowid** 스캔은 단일 행 접근이 매우 빠르기때문에 rowid 스캔이 유리하다고 판단되면서 rowid 스캔을 할수있는 상황이면 유리하다.


Full테이블 스캔을 이용해야하는경우

- 옵티마이저 자체가 풀 테이블 스캔이 낫다고 판단하는경우와 조건절에 비교한 컬럼에 최적화된 인덱스는 있지만 조건에 만족하는 데이터가 테이블의 많은 양을 차지할때.

- 인덱스는 있지만, 테이블 데이터 자체가 적어서 옵티마이저가 풀스캔이낫다고 알아서 판단할때

- DEGREE 속성값이 테이블생성할때부터 크게 되어있는경우
- 조건절에서 비교한 컬럼에 인덱스가 없는경우.

Index 스캔을 사용하는경우

index스캔을 사용해야하는경우는 꽤많다.

- 유니크 인덱스를 구성하는 모든 컬럼이 조건에 = 로 명시된경우
- 유니크성격의 결합인덱스의 선두 컬럼이 whrer절에 사용되는경우. or 일반 인덱스의 컬럼이 where 절에 존재하는 경우.

- index range 스캔을 수행함과 동시에 order by desc절을 만족하는경우.

- 옵티마이저가 index skip scan이 풀 테이블 스캔보다 낫다고 판단하는경우.

- index full scan을 수행함과 동시에 order by desc절을 만족하는경우.


### 파티션 테이블


### 정규화를하는이유

DB공부를하다보면 가장 기본적으로 반복되서나오는것이 무결성, 격리성, 정규화이다.

수도없이 정규화를 외우고 공부했는데도 막상 면접에서 질문받으니 머리가 하얗게변하면서 아무런 대답도할수없었다.
알고있는 지식을 남에게 설명하지못한다면 아는것이 아니라고했던가.. 그말에 뼈저리게 공감하며 정규화에대한 개념을 다시 재정립해야겠다는 생각이들었다.

#### 정규화의 필요성 & 정규화

정규화는 보통

- 중복데이터방지
- 부모와 자식 데이터간의 논리적 관계 유지
- 이상현상방지
- 재개발 비용 감소

등을 위해 수행한다.

책에서 가장 많이 설명하는말로는 **테이블 간 중복된 데이터를 줄여서 데이터 무결성을 개선하기위해 정규화 단계에 따라 데이터 베이스를 구조화하는 과정**을 의미한다.

그럼 <u>데이터 무결성</u>에 대하여 의문을가질수있다.

데이터 무결성은 정확성,일관성,유효성이 유지되는것을 뜻한다.

- 데이터의 정확성 : 데이터의 중복이나 누락이 없는상태
- 데이터의 일관성 : 원인-결과의 의미가 연속적으로 보장되어 변하지않는 상태.

위와 같은 상태를 개선 및 유지시키기위해 단계별로 나눠진 정규화 과정을 거치게된다.

정보처리기사와 SQLD에서 주구장창 나오듯 

- 1NF 원자성
- 2NF 부분 함수 종속
- 3NF 이행 함수 종속
- BCNF결정자 GKATN WHDTHR
- 4NF다치(다중값)종속
- 5NF조인 종속

같이 단계가 정해져있고,보통은 3NF나 그 다음단계까지 적용한다고들었고, 너무많은 정규화작업은 JOIN으로 인해 성능저하를 일으킬수있다.

그러므로 잘못된 데이터베이스 설계는 이상현상과, 데이터의 중복이 발생할수있다는말이다.

<u>이상현상</u>으로는 

- 삽입 이상 : 불필요한 정보까지 같이 입력하여 삽입해야하는 이상현상을 의미한다. EX) 사원이름, 생년월일, 주소,주민등록번호 등의 컬럼이 존재하는 테이블에서 기본키가 주민등록번호라면, '부서'라는 새로운 컬럼을 생성하고 부서의 정보만 삽입할수없다. 왜냐하면 기본키의 정보가없기때문이다. <u>이렇게 원하지않는 정보도 함께넣어야하는것을 삽입이상이라고한다.</u>
- 삭제 이상 : 삭제하고자하는 데이터말고도 다른 데이터까지 삭제해야하는 이상현상. EX) 한명의 사원만 있는 부서에서 그 한명의 이름이나 정보를 삭제해버리면 해당 부서도 같이 사라져버리는 현상. (부서는 테이블이아니라, 컬럼이다.)
- 갱신 이상 : 반복된 데이터 중에 일부를 갱신 할 시 데이터의 불일치가 발생하는 이상현상. EX) 부서의 이름을 바꾸고싶은데, 부서에 소속되어있는 사원의 수가 많을시 부서에 소속된 사원들의 모든 부서이름을 바꿔줘야하는 상황을 갱신이상이라고 부른다.


위와같이 여러 이상현상을 방지하고 데이터의 무결성(데이터의 정확성+ 데이터의 일관성) 을 유지하기위해 **정규화를 수행하는것이다.**


세가지 종류가 존재한다.

### OSPF

### OLAP


## 네트워크

### 프록시

보통, 우리가 아는 프록시는 IP를 우회하는것 이라고 많이 알고있다.
하지만, 프록시의 사전적의미는 **대리, 대신** 이라는 뜻을 가지고있고 프로토콜에 있어서 대리 응답 등 사용하는 개념이다.

<u>주로 보안적인 문제때문에 프록시를 이용하여 중계하는 중계기</u>정도로 이해할수있다.

서버와 클라이언트 사이에서 중계기로써 대리로 통신을 수행하는것을 프록시서버라고한다.

#### 프록시 서버의 사용목적

- 익명성으로 보안을 목적을위해 사용
- 캐시를 이용한 속도 향상
- 차단된 사이트에 접속하기위해 IP세탁을 통해 접속
- 원하지않는 사이트 차단


#### 프록싱/역 프록싱

단, 프록시 서버가 어디에 있느냐에따라 **프록시/역 프록시**로 나뉘는데 프록시 서버위치에 따른 프록시 기능이 어떻게바뀌는지 알아본다.

- Foward Proxy : (클라이언트 <-> 프록시 - 웹서버 ) 의 구조를가지고있으며, 클라이언트와 웹서버의 중계기 역할을한다. 클라이언트의 요청을 1차적으로 프록시 서버에서 처리하는 방식으로, **클라이언트의 요청을 프록시 서버에 캐시로 저장해두거나 캐시에서 꺼내오는 방식** 으로 이용한다. <u>프록시 서버는 클라이언트가 요청하기 전 까지 웹 서버의 주소를 알수없음, 특정사이트의 접근을 막을수도있다.</u>


즉 Foword Proxy는 클라이언트가 요청을 전달하면 프록시 서버가 요청한 사이트의 내용을 웹서버에서 받아오거나 저장된 캐시에서 **대신 전달**


- Reverse Proxy :(클라이언트 - 프록시 <-> 웹서버 ) 의 구조를 가지고있다. 클라이언트와 내부망(프라이빗 네트워크) 서버 사이에 위치한것이고 **제어 역할**을 한다. 클라이언트가 바로 웹 서버에 데이터를 요청하여 받아올수있지만, 보안상으로 좋지않기때문에 내부망 밖에 프록시 서버를 두고 내부망을 보호하는 역할을하는 역 프록싱 기능을한다. <u>클라이언트가 데이터를 요청하면 내부망 밖에있는 프록시 서버에 요청이 들어가는구조이고, 요청을 받은 프록시 서버는 내부망 서버에서 데이터를 받아와서 클라이언트에게 응답한다.</u> 클라이언트의 요청이 정상적인지 프록시가 한번 걸러줄수있기때문에 보안적으로 조금 더 좋다.


Foword Proxy는 **내부망 안** , Revers Porxy는 **내부망 밖**이다.
이러한 프록시는 크게 중계기 역할을하기때문에 프록시 서버를 특정 서버로 지정해놓으면 클라이언트가 보내는 요청을 가로챌수있다.

### HTTP / HTTPS

- HTTP : 데이터를 주고받기위한 프로토콜. MVC가아닌 서버-클라이언트 모델을따름.**상태정보(이전 페이지에대한 데이터 등)를 저장하지않고, 클라이언트의 요청에 맞는 응답을 보낸후 일방적으로 연결끊어버리는 특성을가짐** (비연결적, 상태정보 유실) <u>기본적으로 80번포트 사용</u>

    - 장점 : 서버-클라이언트 모델이므로 상태정보를 관리할 필요가없어 서버 디자인이 간단하다. HTTP요청에 독입적으로 응답만 보내면 OK.
    - 단점 : 상태정보(이전 페이지에대한 통신정보) 를 모르기떄문에 매번 인증해줘야하는 까다로움, 상태정보 저장을 위한 쿠키, 세션 사용. 평문 데이터를 전송하는 프로토콜이라 보안성이좋지않음

- HTTPS : HTTP통신에서 SSL인증서가 추가되면 HTTPS가 된다. 주로 로드밸런싱 기능이나, 통신의 보안성을위해 사용한다. **SSL자체가 보안 통신 규약**이기때문에, HTTPS는 SSL인증서가 발행된 HTTP 프로토콜이라고 생각할수있다.HTTP는 TCP와 직접통신했지만, **HTTPS는 HTTP <-> SSL <-> TCP** 의 구조를 가지고있어서 SSL이 TCP와 통신함으로 암호화,증명서,안정성을 보장/보호한다. 정리하자면 **HTTPS는 서버와 암호화 통신을하고있다는 의미이다.**  HTTP+SSL이 합쳐진 형태이므로 HTTP, SSL ,HTTPS 모두 다 다른 블록이라고 생각하면된다.
<u>TCP기반의 통신이므로 443번 포트를 기본으로 사용한다.</u>

- SSL : 인터넷을 통해 전달되는 정보를 보호하기위해 개발된 통신규약 중 하나.쉽게 말해 웹 사이트의 보안을위해 사용되는 프로토콜이라고 생각하면된다. SSL,TSL 둘 다 통신에대한 보안 프로토콜인데, 클라와 웹서버가 보안이 향상된 통신을 할수있도록 하는 프로토콜이다.

- TLS : SSL과 같은 의미의 단어이다. TLS가 SSL보다 더 나중에 나왔지만, SSL을 더 많이 선호하는편이다.

우리가 인터넷에서 HTTP를 통해 데이터를주고받는것을 택배로 비유하자면,

-오픈형 화물차(보안X) : HTTP
-자물쇠가있는 트럭형 화물차 : HTTPS
-물건 : 데이터

그리고 클라이언트와 서버만 트럭을 열수있는 열쇠를 나눠가지는것이 HTTPS 통신의 전체적 흐름이다.

<u>그럼 어떤방식으로 보안이 적용되는가?</u>

1. 핸드셰이크 : 데이터를 주고받기위해 어떤 방식을 사용하는가에대한 상태파악. SSL은 TCP기반 프로토콜이기때문에 TCP 3-WAY 핸드셰이크를 수행 후, SSL 핸드셰이크를 수행한다.
    - Client hello : 클라이언트가 서버에게 연락하고(브라우저에 도메인입력하는것과같음) 클라이언트는 브라우저가 지원할수있는 암호화방식을 서버에게 제시하고, 랜덤데이터를 생성하여 제시한 암호화방식과 같이 전송.
    - server hello : 서버가 클라이언트에게 연락하여, 제시받은 암호화 방식 중 하나를 선정함과 동시에 자신의 인증서를 함께 클라이언트에게 전송. 이때, 인증서안에는 서버의 *공개키*가 포함되어있다. 또한 랜덤데이터를 추가로 전송.
    - Client key exchange: 클라이언트는 미리 주고받은 자신과 서버의 랜덤 데이터를 참고하여 서버와 암호화 통신할때 사용할 키를 생성한 후 서버에 전달한다. 이때 키는 서버로부터 받은 공개키로 암호화 되어 보내진다.

2. 전송 : 핸드셰이크 단계에서 어떤방식으로 데이터를 주고받는지 협상이 끝나면, SSL세션을 생성하고 클라이언트와 서버는 원하는 데이터를 주고받는다. 이게 전송단계이다.
3. 종료 : 데이터를 모두 주고받았으면 세션을 종료한다.

정리하자면 SSL은 비대칭키 방식으로 암호화에 사용될 키를고르고 대칭키 방식으로 데이터를 통신하는 프로토콜이다. 

### 쿠키 & 세션 & 캐시

#### 쿠키

쿠키는 **비교적 중요도가 낮은 정보를 클라의 컴퓨터에 저장하는 작은 기록정보파일.** HTTP 통신을할때 중요도,보안도가 상대적으로 낮은 상태정보를 클라이언트의 PC에 저장했다가 필요시 참조하거나 재사용하는것.

- 저장형식 : txt
- 만료시점 : 쿠키저장 시 설정(만료시점에따라 브라우저 종료해도 안지워질수있음)
- 사용 리소스(자원) : 클라이언트의 리소스를 소모
- 용량제한 : 도메인당 20개, 쿠키당 약 4kb. 총 300개
- 속도 : 세션보다 빠름
- 보안 : 세션보다 안좋음 

<u> 동작 방식 </u>

    클라이언트가 페이지 요청
        ↓
    웹 서버가 쿠키 생성
        ↓
    생성한 쿠키에 정보를 담아서 HTTP화면을 돌려줄때 클라이언트에게 돌려줌
        ↓
    넘겨받은 쿠키는 클라이언트가 저장/ 서버에 재요청할때 다시 쿠키 전송
        ↓
    동일 사이트 재방문시, 클라이언트가 동일한 쿠키를 가지고있을때, 요청 페이지와 함께 쿠키를 전송

#### 세션 

세션은 **중요하고 보안이 필요한 정보들을 일정시간(기간지정 가능 및 보통은 브라우저 종료 시) 웹 서버가 저장하는 기술이다.** 일정시간동안 같은 사용자로 부터 들어오는 일련의 요구를 하나의 상태로 취급함.

<u>클라이언트가 웹 서버에 접속해있는 시간동안, 세션은 클라이언트에게 고유의 세션 ID를 발행, 세션 ID로 같은 사용자가 접속을 유지하고있는지, 또 같은 세션ID로 저장된 상태정보가 있는지 등을 구분하고, 같은 사용자의 요청인지 아닌지 구분하여 하나의 상태로 묶는다.</u>

- 저장형식 : 오브젝트(Objcet)
- 만료시점 : 만료시점을 설정할순있지만, 브라우저가 종료되면 삭제
- 사용 리소스(자원) : 웹 서버 리소스 소모
- 용량제한 : 서버가 허용하는 한 용량제한이없다.
- 속도 : 쿠키보다 느림
- 보안 : 쿠키보다 좋음


<u>동작 방식 </u>

    클라이언트가 웹 서버 접속
        ↓
    서버는 클라의 쿠키를 확인하여 클라가 해당 세션 id를 보냈는지(쿠키에담아서)확인
        ↓
    웹서버는 존재하지않는 세션 id인지 확인하고, 존재하지 않는 세션 id라면 새로운 id를 생성해서 클라이언트에게 넘겨준다
        ↓
    클라이언트는 서버로부터 받은 세션 id를 쿠키에 저장
        ↓
    클라이언트가 서버에 요청시 이 쿠키의 세션 id값을 같이 웹 서버에 전달
        ↓
    서버는 전달받은 세션 id로 세션에 있는 클라이언트 정보를 가지고 요청을 처리한다.


**쿠키와 세션의 가장 큰 차이점은 저장위치와, 라이프 사이클(정보의 만료기간) 이다. 쿠키는 파일로 저장되기때문에, 브라우저를 종료해도 만료기간을 따로 지정해서 쿠키를 삭제하기전까지 유지할수있다. 반면 세션은 만료기간을 정할수있지만, 브라우저가 종료되면 삭제된다.**

#### 캐시

<u>네트워크에서의 캐시의 기능은, 웹 페이지 요소를 저장하기위한 임시저장소.</u>

즉, 회원정보 등, 클라이언트의 요청에따른 *클라이언트 정보를 저장하는것이아닌, 웹 페이지의 스크립트, 구성요소 등을 임시로 저장하고있다가 요청이 들어오면 빠르게 응답해주는것.*

그렇기때문에 요청이 들어올때마다 웹 페이지를 새로그리는것이아니라, 캐시를 이용하여 웹 페이지의 전체적 뼈대를 저장하고있다가, 웹 페이지의 요청이 들어올때마다 웹 페이지의 구성요소들을 반환한다. 

캐시의 특징은

- 저장공간이 작고 비싸지만 빠름
- 같은 웹페이지에 접속할때 사용자의 pc에서 로드하므로 서버를거치지않음

고로 쿠키와 세션 과는 다르게 캐시는 웹 페이지의 요소를 저장하는것이다.

### OSI 7 Layer(os7계층)

    7 응용(app) : 인터페이스 역할
    6 표현(presentation) : 데이터의 형식을 정의.
    5 세션(session) : 컴퓨터끼리 통신하기위해 세션을 만드는계층
    4 전송(transport) : 데이터의 전송을 담담하는 계층( TCP / UDP가 여기속함)
    3 네트워크(network) : 패킷을 목적까지 가장빠른길로 전송하기위한 경로설정 (전송단위는 패킷이다.)
    2 데이터링크(datalink) : 데이터의 물리적인 전송,에러검출,흐름제어 등을 담당(이더넷이 여기에속하고 단위는 프레임)
    1 물리(physical) : 데이터를 전기신호로(물리적)으로 바꿔주는계층(리피터,허브등 물리적 장치들이 이곳에 속함)

    그외, 텔넷,FTP,SMTP,HTTP,SNMP등은 어플리케이션~세션(7~5)계층에 속한다.


-패킷: 컴퓨터간에 데이터를 주고받을때 네트워크를 통해 전송되는 **데이터의 조각이라고 생각하면되고 이 조각의 단위를 패킷이라고부른다.** 이렇게 데이터를 쪼개서 보내는이유는 <u>대역폭을(신호를 전송할수있는 주파수의 범위 또는 폭) 많이 차지하지않게하기위해서</u>이다. 데이터가 클수록 차지하는 대역폭이 커지고 트래픽이많아져서 패킷의 흐름을 방해하게된다. 그런 이유에서 데이터를 조각으로 쪼갠 패킷을 사용하는것이다.


### UDP & TCP

-UDP : 비연결지향적 프로토콜. TCP와 좀 반대되는것들이많다. 연결절차를 거치지않고 발신자가 일방적으로 데이터를 발신하는 방식으로 **신뢰성이 떨어지나 속도가빠르다.** 다만 잘못된 선로로 데이터가 전송될경우 데이터가 유실될 가능성이있다. 이렇게 유실된경우 **TCP와 다르게 UDP는 패킷도착확인 및 재전송을하지않는다. 3-way 핸드셰이킹을 사용하지않기때문에 빠르고 신뢰성떨어짐.** 주로 <u>스트리밍 등 실시간 데이터에적합</u>

UDP는 순서보장을하지않음.

-TCP : 연결지향적 프로토콜. 클라이언트와 서버가 연결된 상태에서 데이터를 주고받는 프로토콜을 의미하는데, **UDP보다 신뢰성을 보장하고 속도가느리다.** 왜냐하면 데이터를 송신할때마다 확인 응답을 주고받는 절차가있기때문이다. 1:1 통신만 가능하다. **3-way 핸드셰이킹을 통해 연결을 설정하기때문에 높은 신뢰성을 보여주지만 속도가 느리다.** <u>신뢰성이 중요한 파일 교환과 같은경우에 쓰임</u>

TCP는 순서보장을함.


### 3-WAY 핸드셰이크 & 4-WAY핸드 셰이크

- 3-WAY : TCP 네트워크에서 통신하는 장치가 **서로 연결이 잘되었는지 확인하는 방법** 송,수신자는 **총 3번에 걸쳐서** 데이터를 주고받으며 통신이 가능한 상태인지 확인한다.

간단한 동작 방식으로

    #1. Client -> Server : 내 말 들려?

    #2. Server -> Client : 어 잘 들려! 내 말은 들려?

    #3. Client -> Server : 잘 들려

    위와같은 과정을

    CLOSED : 연결없음,초기상태

    LISTEN : 포토가 열린상태로 연결 요청 대기중

    SYN-SENT : SYN를 요청한 상태 (SYN:연결확인을 위해 보내는 무작위의 숫자값. ACK(보낸 SYN에 +1을한값으로 돌려줘서 잘받았다는 의미의 회신)로 회신한다.)

    SYN-RECEIVED : SYN 요청을 받고 상대방의 응답을기다림

    ESTABLISHED : 연결 수립이 완료된 상태. 서로 데이터를 교환할수있는 상태를 의미한다.

- 4-WAY : TCP 네트워크에서 통신하는 장치의 **연결을 해제하는 방법** 송,수신자는 **총 4번에 걸쳐서** 데이터를 주고받고 연결을 끊는다.

4 WAY의 간단한 동작방식은

    #1. Client -> Server : 나는 다 보냈어! 이제 끊자!

    #2. Server -> Client : 알겠어! 잠시만~

    #3. Server -> Client : 나도 끊을게!

    #4. Client -> Server : 알겠어!


**TCP와 UDP를 그림으로 비교**

TCP

![TCP](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2Fx7IGo%2FbtrsW8REhYz%2FjlnTXXNDAb4S6Qg4QCxwDk%2Fimg.png)


UDP

![UDP](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2F2ndZ1%2FbtrsW9bZXKB%2FOSV6HaJn7hTxO3eBKXSOV1%2Fimg.png)

위와 같이 TCP는 여러번 확인과 절차를 통하기때문에 느린거고, UDP는 일방적으로 보내기때문에 빠르다.


#### HTTP Method 와 각각 사용되는 경우에 대하여 설명.

GET, POST, PUT , DELETE 등의 HTTP 동작을 일으키는 메소드이다.
**주로 클라이언트가 서버에게 사용자 요청의 목적을알리는 수단이다.**

종류로는

- GET : 데이터 조회
- POST : 요청한 데이터를 처리하는동작. 주로 어떠한 데이터를 등록하는데 사용.
- PUT : 데이터 변경(해당 데이터가없으면 생성). 데이터를 밀어넣는다는 표현이옳음
- PATCH : **일부**데이터만 변경한다.
- DELETE : 데이터 삭제



HTTP메소드는 주로 RESTFUL API 개념과 같이 설명할수있는데, 자원을 URL로 표현하고 자원에대한 행위를 HTTP메소드를 통해 조작하는것을 RESTFUL 이라고 부르고, **RESTFUL API는 RESTFUL한 방식을 따르는 API를 일컫는말이다.**

<mark>그럼 PUT 과 POST의 차이점과 HTTP메소드는 CRUD에 어떻게 매칭될까?</mark>

HTPP 메소드의 각 행위들은 <u>CRUD(생성,읽기,갱신,삭제)에 각각 매칭되는데, 생성은 POST가 담당하고, 갱신,변경등의 행위는 PUT이 담당한다.</u>

<u>GET과 POST의 차이</u>

일단 GET은 주로 HTTP통신을 이용해 웹 서버에서 **데이터를 조회하거나 가져올때 사용한다.** 

GET의 가장 큰 특징으로는 **데이터를 헤더에 추가하여 전송하므로, URL에 정보가 노출되어서 전송되므로 보안적으로 취약하다.** 그래서 GET을 사용할때는 보안적으로 중요한 데이터를 포함하지않아야한다.

반대로 <u>POST는 데이터를 추가,등록,또는 수정하는 동작을한다.</u> PUT과 비슷해보이지만 PUT은 데이터를 변경하거나 해당 데이터가 없을 시 생성하고는거고,
**POST는 데이터를 바디부분에 추가하여 전송하는 방식으로 데이터를 처리하기때문에, URL에 데이터가 노출되지않은채로 전송되므로 GET보단 보안성이 우수하다.**

하지만 POST방식이 완전히 안전한것은아니다. GET방식과 비교했을때 비교적 안전하다는것이고, 이것이 GET과 POST의 차이점이다.


### 세션기반인증과 토큰 기반 인증

#### 세션기반 인증

세션기반 인증은 클라이언트로부터 요청을 받으면 <u>클라이언트의 상태 정보를 저장하므로, 상태성(Stateful)한 구조를 가진다.</u>

단점으로는
    1.서버에 세션을 저장하기때문(상태성)에, 사용자가 증가하면 서버에 과부화가 올 수 있어서 확장성이낮다.

    2.해커가 훔친 쿠키를 이용해 요청을 보내면 서버는 그것이 해커가보낸 요청인지, 진짜 클라이언트가 보낸 요청인지 구분할수가없다. (세션 하이재킹 == TCP취약점을 이용해 정상적인 세션접속상태를 훔치는것.)

세션기반 인증을 사용해야할때는 언제인가?

단일 도메인이라면 세션기반 인증을 사용하는것이좋다.

왜냐하면, **세션을 관리할 때 사용되는 쿠키** 는 <u>단일도메인 및 서브 도메인에서만 작동하도록 설계되어있기때문</u>에 여러도메인에서는 CORS정책 문제(교차 출처 리소스 제공)를 일으킬수있다.

여기서 교차는 CROSS를 의미하는데, 한국어로는 "다른 출처" 라고 이해하는게 덜 헷갈린다.

#### 토큰기반 인증

토큰기반 인증은, <u>상태정보를 서버에 저장하지않으므로 무상태성(Stateless)한 구조를가진다.</u>

그럼 토큰 기반인증은 어느때 각각 적합할까?

단일 도메인이 아니고 <u>여러도메인일때 토큰 기반 인증을 사용하는것이 적합하다</u>

#### CSRF공격, CSRF TOKEN

HTTP는 무상태성(Stateless)와 비연결성(Connectionless)의 특성을 가지고있다.

CSRF공격은 사이트간 위조 공격이다. 공격자가 클라이언트에게 CSRF공격 코드를 심어놓은 악성 URL에 접근하도록 유도하고, 공격대상인 웹(HTTP)에 클라이언트가 의도하지않은 동작을하도록 시키는것이 CSRF공격의 흐름이다.

HTTP 프로토콜의 무상태성과 비연결성 특성을 보완하기위해 쿠키와 세션을 이용하게되는데, 세션과 쿠키를 이용하여 사용자를 인증하고 세션을 추적하는 웹 어플리케이션에서 발생하는 취약점을 이용한 공격기법이다.

CSRF TOKEN은 그러한 CSRF공격을 막기위해 난수의 토큰값을 접속자에게 발행하여 해당 접속자가 요청을보냈을때 토큰값을 대조하여 정상적인 요청인지를 확인한다.

### JWT 토큰이란?

JWT는 JSON포맷을 이용하는 Claim기반의 웹 토큰이다. **토큰 자체를 정보로 사용하는 Self-Contatined방식으로 정보를 안전하게 전달한다.**

JWT는 헤더,내용,서명으로 구성되고 각 파트를 . 으로 구분한다.

- 헤더 : 토큰 타입과 해시 암호화 알고리즘으로 이루어져있음
- 내용 : 토큰에 사용자가 담고자하는 정보를 담는것. JSON 형태의 한 쌍으로 이루어져있다.
- 서명 : 토큰을 인토딩하거나 유효성을 검증할 때 사용하는 고유한 암호화 코드. 헤더-내용 값을 인코딩한다.


즉, JWT 토큰은, 토큰기반 인증시스템이라고 볼수있다.

### 대칭키 & 비대칭키 암호화 방식

대칭키는 암호화키와 복호화 키가 동일한 알고리즘
대칭키의 단점을 극복하기위해 비대칭키 암호화 방식이 나왔다.

<u>대칭키</u>

    암호화와 복호화에 같은 암호키를 쓰는 알고리즘.
    다만, 대칭키는 누군가 암호키를 가로채면 암호화된 정보가 유출될 수 있다는 단점이있는데, 이런 문제를 극복하기위해 나온게 비대칭키(=공개키)

<u>비대칭키(공개키)</u>

    암호화와하는 키와 복호화하는 키가 다른 암호화 알고리즘이다.
    타인에게 절대 노출되서는 안되는 개인키(.pub키말고 그냥 private key)와 공개적으로 개방되어있는 공개키(.pub파일)을 한 쌍으로 이룬 형태.

### Connection Timeout 과 Read Timeout

#### Connection Timeout

**서버자체에 클라이언트가 접근**할때, **어떤 사유로 접근을 실패했을시** 적용되는것을 의미한다.

즉, 접근을 시도하는 <u>접근시도 시간제한</u> 정도로 이해할 수 있다.

### Read Timeout

Connection Timeout과 달리, <u>서버자체에 클라이언트가 접속에 성공했으나, 서버가 로직을 수행하는 시간이 너무 길어서 실패하는경우</u>가 **Read Timeout이다.**

말그대로, 접속의 문제가아니라 서버의 로직을 읽어들이는 시간이 초과되어 발생하는것을 일컫는다.

Read Timeout이 발생하는경우는 보통 클라이언트가 해당 오류를 인지하고, 서버는 계속 로직을 수행하고있어서 이것을 성공으로 인지해서 **양 사이드간의 싱크가 맞지않아 문제가 발생할 확률이 높다.**


### 퍼블릭 IP(공인IP)와 프라이빗IP(사설IP)


#### 공인IP

- 공인 IP는 ISP(인터넷 서비스 공급자. SK,KT등?)가 제공하는 IP주소이다. 외부에 공개되어있는 IP로써, 타인들이 공개IP를 이용하여 웹 서버에 접속을시도할수있다.

- 사설 IP는 일반 가정, 회사 등 내부에 할당된 네트워크 IP주소이며, IPv4의 주소부족문제(IPv6의 등장배경과같음) 서브넷팅된 IP이기때문에 라우터(공유기)에 의해 로컬 네트워크상의 PC나 장치에 할당된다. 즉, 내부에서만의 통신을위해 사용되고 할당되는 IP주소같은것


- 사설IP 주소를 이용하여 타인이 접속을시도하거나 인터넷에 직접 연결할수는없고, 라우터를 통해 1개의 공인 IP를 할당하고,라우터에 연결된 개인 PC는 사설 IP를 각각 할당받아 인터넷에 접속할 수 있다.


### 네트워크 URL의 기본 구조

![URL의 기본구조](https://evan-moon.github.io/static/e25190005d12938c253cc72ca06777b1/6af66/uri-structure.png)

### DNS 서버와 DNS의 정의 및 작동원리

네트워크, 웹을 공부하다보면 늘 만나는것이 DNS이다. 
DNS서버와 DNS의 정의가 무엇이고 도메인과는 어떤 차이점이있는지 알아보자

#### 도메인

- **도메인** = **IP를 문자화시킨것이라고 볼수있다. IP주소 대신 사용하는 주소**

- nslookup : 터미널에서 도메인의 IP주소를 확인할수있는 명령어.

#### DNS(도메인 네임 시스템)

네트워크상에 존재하는 <u>모든 PC는 IP주소가있지만, 반대로 모든 IP주소가 도메인을 가지진않는다.</u>

리눅스 etc/hosts에서 해당 PC에 IP주소를 내가 내부에서 부를이름으로 매핑시키는 작업과 비슷하다고 생각하면된다.

**이 작업이 네트워크상에서 이루어진다고 생각하면되고, 네트워크상에서 이렇게 매핑시켜주는 일을하는것이 DNS서버이다.**

도메인과 IP주소를 매칭시키는 과정을 조금 살펴보자.

    1.브라우저에 검색창(네트워크상)에 도메인을 이용하여 해당 사이트로 이동하기위해서는, 해당 도메인 이름과 매칭된 IP주소를 확인하는 작업이 반드시필요하다.

    2.위의 작업을하기위한 서버가 별도로있는데 그것이 DNS서버이다.

**DNS**는 일종의 **데이터베이스 시스템**이라고도 볼수있는데, 호스트의 도메인 이름을 IP주소로 변환하거나 반대의 경우를 수행할수있도록 개발된 데이터베이스 시스템이다. 

그래서 <u>DNS시스템 안에서 이어주는 역할을 하는 서버를 풀네임으로 DNS서버라고한다.</u>

**네임서버 == DNS서버** 같은말이다.

DNS의 처리순서
    1.브라우저의 검색창에 naver.com을 입력한다.

    2.이 요청은 DNS에서 IP 주소(125.209.222.142)를 찾는다.

    3.그리고 이 IP 주소에 해당하는 웹 서버로 요청을 전달하여 클라이언트와 서버가 통신할 수 있도록 한다.


### PORT(포트)

- Port(포트)란 IP 내에서 애플리케이션 상호 구분(프로세스 구분)을 위해 사용하는 번호이다.
- 포트 숫자는 IP 주소가 가리키는 PC에 접속할 수 있는 통로(채널)을 의미한다.

## 시스템 엔지니어

### 방화벽과 웹 방화벽의 차이점

#### 방화벽

- 방화벽은 OS7계층의 4계층인 네트워크 계층의 TCP/IP계층의 IP와 PORT정보를 이용하여 접근을 통제한다.

- 주로 IP와 PORT의 신뢰 여부를 기준으로 접속의 성격을 구분해주는 접근제어기반 보안 솔루션이다.

- 문제를일으키는 트래픽이 들어오는것을 제한하는 일종의 라우터라고도 볼수있는데, 로깅 및 감사 추적은 룰셋의 설정/변경, 관리자의 접근, 네트워크 트래픽 허용 여부 관련사항을 기록하여 사고가났을시, 확인하고 추적하기위한 기능이다.

- 인증은 접속자의 신뢰도를 확인하는것으로 메세지인증, 사용자인증, 클라이언트 인증등이있다.

- 데이터의 암호화기능은 방화벽에서 다른 방화벽으로 데이터를 암호화해서 전송하는것으로 보통 **VPN기능이다.**

- **방화벽은 주로 외부망 - 방화벽 -내부망 과 같은 구조로 이루어지고, 외부의 패킷을 분석해 출입 여부를 결정한다.**

- **단점으로는 네트워크 계층으로 암호화된 내용을 복호화할수없어서 웹 공격에대한 탐지/방지에 한계가있다.**

#### 웹방화벽

- 웹 방화벽은 OS7계층의 7계층인 어플리케이션 계층에서 HTTP프로토콜을 문자열 비교방식으로 감시하여 침입시도 및 탐지를 차단한다.

- 방화벽과 달리 웹 서버만 보호하기위해 설계된 정보보호 시스템으로, 사용자 URL의 정상여부를 판단하여 웹 사이트의 위변조를 탐지 및 차단하는 솔루션이다.

- 웹방화벽은 웹 해킹시도로부터 홈페이지를 방어하기위해 HTTP트래픽을 검사하여 해킹을 차단하는 정보보호 시스템이라고 볼수있다.

### 라우팅프로토콜

라우팅 프로토콜의 정의는 **패킷이 목적지까지 가는 방법을 결정해주는 프로토콜이다.**

종류로는 

- RIP
- OSPF
- IGRP
- BGP


등이 있고, RIP, OSPF,EGRP 는 <u>내부 라우팅 프로토콜</u>이고, BGP, EGP는 <u>외부 라우팅 프로토콜</u>이다.

### FTP 액티브 모드와 패시브모드의 차이점


들어가기에 앞서, FTP의 정의부터알아보자.

#### FTP란?

파일을 전송하는 통신규약이다. FTP서버에 파일들을 업로드, 다운로드할수있도록 해주는 프로토콜이고, FTP서버 - FTP클라이언트간에 통신에서 이루어진다.

기본적으로 액티브모드에서는 21번포트와 TCP를 사용하며,데이터 채널 포트로는 20번/TCP를 사용한다.

*단, FTP서버에서 얼마든지 수정할수있다.*

#### FTP 액티브모드

- 데이터 채널 요청을 서버 -> 클라이언트 방향으로 접속한다.

- 요청을 서버 > 클라이언트방향으로하기때문에, 서버의 방화벽 설정을 20번포트가 OUTPUT방향으로 허용설정이 되어있어야한다.

- 클라이언트는 액티브모드에서 받는쪽이기때문에 INPUT 방향으로 허용설정이되어있어야한다.

#### FTP 패시브모드

액티브모드의 단점을 극복하기위해 나온 모드.

패시브모드는 <u>데이터채널 포트 범위를 지정할수있는데, 별도로 지정하지않을경우 1023 < x < 65535 범위 안에서 임의의 포트 번호를 사용하게된다.</u>

- 데이터 채널 요청을 클라이언트 -> 서버 방향으로 접속한다.

- 별도의 포트번호를 지정하지않았을시, 방화벽 설정시 서버의 1024~65534포트를 INPUT방향으로 모두 허용시켜줘야한다.

- 반대로 클라이언트는 1024~65534범위릐 포트를 OUTPUT방향으로 모두 허용시켜줘야한다.


### curl의 정의와 사용하는이유

#### CURL이란?

서버와 통신할 수 있는 커맨드 명령어 툴이다. 웹개발에 매우 많이 사용되고 있는 무료 오픈소스이다 curl의 특징으로는 다음과 같은 수 많은 프로토콜을 지원한다는 장점이 있다.

SSL을 포함한 HTTP, HTTPS, FTP등 많은 프로토콜을 지원한다.

주로 다양한 통신 프로토콜을 이용하여 **데이터를 전송하기위한 라이브러리와 커맨드 라인 도구를 제공하는 오픈소스 프로젝트.**

- -i : 헤더를 포함하여 서버의 응답 내용을 표시한다. [curl -i url]과 같은 포맷으로 사용.
- -X : 리퀘스트에서 사용할 메서드종류를 명시한다(여기서 메소드란 HTTP메소드인 GET, POST,PUT등을 의미)

#### 사용하는이유

보통 URL로 데이터를 전송하고 서버에 데이터를 보내거나 가져올때 사용한다.
셸에서 REST API 테스트를 하고싶으면 CURL명령어를 이용하면된다.

<u>기본포맷</u>

> curl [options / URLS]

### 시스템 구축에 필요한 네트워크 구축의 기본 프로세스 단계

시스템 구축에 필요한 네트워크 구축에 필요한 기본 프로세스들에대해서 알아보자.
단계나 구성요소를 알아볼것이다.


#### 네트워크 구성요소

1. 네트워크 카드(NIC) : = 랜카드 = 네트워크 인터페이스카드. 주로 MAC(랜카드에부여되는 고유한 물리주소)주소와 직렬화, 흐름제어등의 역할을한다.
2. 케이블과 커넥터 : 유선 랜선. 요즘은 무선이많지만 유선을 선호한다면 연결해야함
3. 허브 : 여러대의 장비를 연결할 목적으로 사용하는데, 중앙에 허브가있고 문어발식으로 뻗어나가는것이 허브다. **케이블과 동일한 1계층 장비이다.** 단점으로는 허브에 접속된 단말들이 서로 경쟁하게되므로 전체 네트워크 성능이 좀 줄어들게된다. 또한 **패킷이 무한 순환하여 전체마비를 시키기도한다.**
4. 스위치 :**여러장비를 연결/ 통신, 중재하는 2계층 장비**. 허브의 역할 +통신 및 중재, 총 두가지의 역할을하기때문에 **스위칭허브**라고 도 불리기도한다. 스위칭허브 == 스위치. <u>중재하기때문에 네트워크성능이 향상되고 보안성도 좋아진다.</u>
5. 라우터 : 서로다른 네트워크를 연결하여 데이터를 주고받기위해 연결되는 포트로 패킷(데이터조각)을 보낼 최적화된 경로를 지정하며, 라우터가 지정한 경로를따라 패킷이전송된다.
6. 로드밸런서: 서버에 가해지는 부하를 분산해주는 장치, 또는 기술. **4계층 포트주소를 확인하는 동시에 IP주고슬 변경할수있다.**. 가장 많이사용하는 서비스로는 웹이고 ADC라고 부르기도한다. 즉 <u>로드밸런서 = ADC</u> 여러 사용자의 접속을 로드밸런서가 각각의 서버에 알아서 분배해주기때문에 서버에 가해지는 부하를 줄일수있다.
7. 보안장비(방화벽/IPS) : OS계층 중 4계층에서 동작하며, 정보를 잘 제어하고 공격을 방어하는데 초점이 맞추어진 장비.
8. 모뎀,공유기 등 : 모뎀 = 짧은거리를 통신하는 기술과 장거리 통신을 할 수 있는 기술이 다를때 이 기술들을 서로 변환해주는 장비. 공유기: 하나의 공인IP(퍼블릭IP)를 사용하여 여러개의 기기가 인터넷을 사용하기위해 쓰는 네트워크기기.
9. 게이트 웨이 : 프로토콜이 아닌 다른 네트워크 결합
10. 리피터 : 신호를 증폭시키는 1계층 장비이다.
11. 브리지 : 스위치와 같은 계층(2계층)장비이며, 스위치와 같은 역할을한다. 스위치와 브리지의 차이점으로는 **스위치는 H/W기반이라 역할이 빠르고, 브리지는 SW기반이라 느리다.**

**허브의 구조**

![허브](./네트워크/hub1.PNG)

<u>허브는 한 장비에서 전송된 데이터를 허브에 연결된 모든 장비에게 전송함으로써, 이를 플러딩이라고하고 결과적으로 많은 충돌을 일으킨다. 그래서 하나의 허브에 많은 장비를 연결할수없으며 같은이유로 보안성도떨어진다.</u>

즉 허브는 이더넷 프레임의 충돌이 발생할 가능성이높고(하프 듀플렉방식으로 동작해서) 네트워크 성능도 떨어져서 가정이나 고슈모 기업에서 pc연결하는경우를 제외하고는 거의 사용하지않는다.

- 하프 듀플렉스 : 쌍방향통신,이중통신. 두 지점 사이에서 정보를 주고받는 전자 통신 시스템. 한쪽이 송신하는동안 다른 쪽에서 수신하는 통신방식으로 전송방향을 고체함.

- LAN : 근거리통신망. 가까운거리(거의같은건물)에있는 연결에 이용. 1계층 및 계층요소 2데이터 연결 장비를 사용한다.
- WAN : 장거리통신망. 여러개의 상호연결된 LAN으로 구성될수있다는 특징이있음. 또한 디바이스가 넓은 지역에서 통신할수있도록 장거리에걸쳐 여러 LAN을 연결하는 네트워크라고 이해해도된다. 1,2계층을 이용하고 3계층 네트워크 디바이스사용.

![스위치](./네트워크/switch1.PNG)


스위치는 허브와 다르게, <u> 데이터를 전송할 MAC주소와 포트번호가 기록된 MAC 주소 테이블을 가지고있어서, 목적지 MAC주소를 가진 장비가 연결된 포트로만 데이터를 전송한다. </u>

즉 스위치는 목적지 MAC주소와 포트번호를 스위치가 중간에서 받아서 스위치가 가진 MAC주소 테이블을 스위치가 참조하여 해당 PC가 연결되어있는 포트로만 프레임(데이터나, 요청 등)을 전송한다.

그래서 다른 포트가 전송하는 프레임과 충돌이 일어나지않고 네트워크 성능 향상과 보안성도 좋아진다.

**단, 스위치에 접속된 장비가 많아질수록 브로드캐스트 트래픽이증가하여 네트워크 성능저하가 심각해진다. 이 문제를 해결하기위해 VLAN이 나옴 (VLAN이 다르면 브로드캐스트 프레임이 차단되어 네트워크 성능저하를 막는 원리)**


스위칭 방식으론

1) sotre and forwarding : 데이터를 모두 받은(저장) 후 스위칭

2) cut - through : 목적지 주소만을 확인후 스위칭

3) fragment free :  1과 2의 장점 합산


![라우터](./네트워크/router.PNG)

위에서 설명한것과같이 서로다른 네트워크를 연결시키고, 데이터를전송하기위해 패킷이지나갈 최적의 경로를 지정하는 역할을한다. 또, 원격지에 위치한 네트워크들을 연결하는 경우가많다.

#### 백본

백본이란 네트워크 연결 시 중추적 역할을한다.

백본 스위치라고있는데, 백본에서 스위칭 역할을하는 L3스위치 장비로, 서로 다른 네트워크 연결.

#### 스위치 분류

**L2, L3, L4, L7 등** 공고에 올라온것이 스위치의 분류를 의미한다.


- L2 : 뒤의2는 2계층이라는의미. 2계층 장비. MAC주소를 읽어 스위칭, 동일 네트워크 간 연결 등을 지원

- L3 : 3계층장비. IP주소를 이용하여 라우팅한다.(스위치이지만 라우터 기능이 추가되어 3계층장비에 해당하게됨)
  
- L4 : L3에 로드밸런서, 페일오버기능이 추가되어 4계층 장비에 속하게된것.**주로 TCP/UDP를 통해 요청받은 작업을 여러서버로 분산**

- L7 : 패킷내용을 참조하여 <u>세밀하게 로드밸런싱한다. </u>

#### hierarchical 3 layer (계층형 3레이어 모델)

계층형 3 레이어 모델은 안정적인 네트워크를 구축하고자 하는 경우 많이 활용되는 네트워크 구축 모델 중 하나이다. 통신을위한 IS의 각 계층을 3개의 계층으로 구분하고, 용도에 맞는 장비를 적절하게 배치하여 네트워크를 구성한다. <u>계층 간 구성이 단순하며 확장성이 좋은 대용량 네트워크를 쉽게 디자인할수있다는 장점이있음</u>

- core : 백본 스위치에 존재하는것. 포트수가 적어도 되지만 장비 성능이 좋아야한다. 모든 패킷이 지나가는 중심이 되기때문에 배치되기전에 **대규모 트래픽을 처리** core계층은 주로 조직내부에서 전산실에 위치하고 디스트리뷰션 계층과 장비를연결한다.
  
- distribution : 주로 라우터를 활용하며, 장비는 일반적으로 건물 내 전산실에 위치하여 액세스와 코어 계층 사이에 존재하여 두 계층 장비와 연결한다.
  
- access : 주로 **스위치**를 활용하며 장비는 일반적으로 건물의 각 층에 위치하여 ES들과 연결한다.

#### 프로세스단계

1. 진단 / 분석단계. 주로 네트워크를 구축하고자하는 환경이 어떤지 진단하고, 요구분석이나 네트워크 구축에 필요한 자원 등을 파악.
2. 디자인 단계(네트워크 설계) / 토폴로지 결정. 해당 환경에서 네트워크 요소들을 어떤 형태로 연결해놓을지 결정
3. 설치 / 구축 단계
4. 운용단계

#### 토폴로지

토폴로지는, <u>컴퓨터 네트워크의 요소들(링크나 노드 등) 을 물리적으로 연결해놓은것이나 그 연결방식을 의미한다. </u>

주로 디자인 단계(설계) - 토폴리지 결정이라고도 부르며, 이 단계에서는 어떤 네트워크를 어떤 형태로 디자인할것인가 디자인 구조를 정리해놓은것중에서 정한다고 생각해도된다.

즉, 토폴리지 = 네트워크 설치구조 이며, 흔히 우리가 잘 알고있는 성형, 트리형(계층형), 버스형, 망형이있다.


- 성형 : 노드(클러스터를 이루는 하나의 구성원 역할을하는 컴퓨터 또는 서버)가 허브라는 네트워크 장비에 점 - 점 으로 연결되어있는구성.
    
    특징

    1.소규모네트워크에 유리
    2.재구성이 간편하여 추가 제거가쉽다
    3.하나의 단말장치 등, 개별적인 단말장치들이 고장나더라도 전체 네트워크에 영향을 주지않는다.
    4.단, 중앙 허브가 고장나면 단말장치가 고장나지않아도 네트워크에 영향을준다.

- 망형 : 각 노드들이 다른 모드 사이트와 직접 연결된구조이다.
    
    특징

    1.기본비용이 비싸지만, 신뢰성이 높고 메세지 전달 속도가 빠름
    2.모든 노드를 망형으로 연결했을시, n-1개의 포트가 필요하다.
  
- 링형구조 = 환형 : 각 노드가 원을 그리며 양쪽의 컴퓨터와 점 대 점으로 연결되어 순환형으로 구성되어있다.

    특징

    1.노드추가,삭제 등 재구성용이.
    2.새로운 노드 추가시, 통신회선을 절단해야한다.

- 트리형구조 = 계층형 : 분산처리 시스템의 대표적인 형태인 아래로 뻗어나가는 나뭇가지 형태의 구조로 컴퓨터가 연결되어있다.

    특징

    1.허브만있으면 많은 노드들을 쉽게 연결할수있음
    2.단, 허브가 고장나면 허브아래에 연결된 단말노드들 모두 장애를일으킴
    3.허브뿐만아니라, 부모노드가 고장이나면 부모노드 아래에 연결된 자식노드도 장애를일으킨다.

- 버스형 구조 : 하나의 통신회선에 여러대의 컴퓨터가 멀티 포인트로 연결. 버스노선도같은 구조라고생각하면됨

    특징

    1.물리적 구조 간단, 설치 용이, 비용 감소, 컴퓨터 추가/삭제용이
    2.통신 회선이 고장나면(버스노선에 문제가생기면 ㅇㅇ), 전체 네트워크에 영향이간다.
    3.단, 노드고장, 연결된 컴퓨터 고장 (버스정류장 자체의 고장)은 전체 네트워크에 영향주지않음.

## 클라우드 엔지니어

### 온프레미스 / 하이브리드 클라우드 / 클라우드 환경

- 온프레미스 : 회사,기업이 자체적인 기술과 구조로 구성된 서버를 구축하고있는것. 보통 회사내부에 물리적인 자체 서버를 가지고있는경우가많음

- 하이브리드 클라우드 : 클라우드 + 온프레미스를 합친것. 장점으로는 **자주사용하지않는 데이터를 저렴하게 보관,저장하는것**이다. 클라우드의 리소스가늘어나면 비용도 비싸지기때문에, <u>자주활용하는 데이터나 자주 활용하지않는 데이터나 어플리케이션을 분류하여 각각 온프레미스에 저장하든지, 클라우드에 저장하든지 선택한다. 하지만 클라우드의 보안 취약점이 있기때문에 온프레미스에 자주사용하는 데이터들을 넣어놓는것도 나쁘지않은 방법이라고한다.</u> 즉, 하이브리드의 장점은 유연성과 비용이다. 

- 하이브리드 클라우드 단점 1 : 하이브리드라서 생기는 보안적 취약점이 발생한다. 특히 데이터 보호가 가장어렵다. 

- 하이브리드 클라우드 단점 2 : 하이브리드 클라우드를 관리하면서 점점 체계가 이원화되기 시작하여 별도의 시스템처럼 운영하게되어 하이브리드의 특장점이 사라진다.

- 하이브리드 클라우드의 단점 3: 다수의 스토리지를 동시에 감독하고 모니터랑하는 과정이나 기술, 방법을 일원화하기 어렵다.

- 클라우드 : IDC센터 등 거대한 규모의 저장장치를 운영하는 기업에서 서버,저장소를 필요한만큼만 빌려서 사용하는 방식. 비즈니스의 연속성이좋다(서비스가 기업내부의 문제로 끊기지않고 유지되는것).

- 프라이빗 클라우드 : == 온프레미스를 의미함

※스토리지란? : 데이터를 저장하는 물리적장치. DAS, NAS, SAN등이있다.
    
    DAS :  다이렉트의 D이다. 호스트(서버,클라이언트 등)가 저장공간이 부족할때, 가장 쉽게 저장공간을 확보할수있는방법. 스토리지와 장치(호스트)를 직접연결하여 데이터를 저장하는방식이다. 단, 확장성이없어서 물리적 공간의 한계에 다다랐을때 확장이 어렵다는 단점이있다.

    NAS : 네트워크의 N이다. 스토리지와 네트워크를 연결하여 데이터를 저장하고 관리한다. DAS의 사이에 네트워크가 중계인처럼 끼어져있는 형태라고 생각하면된다. FTP(파일전송 프로토콜. 네트워크계층의 프로토콜임으로 네트워크를 통해 파일을전송하는 규약이다.) 또한 NAS의 프로토콜 중 하나이다.
    장점으로는 NAS스토리지를 여러개 늘려 클러스터를 구성하는것이 가능하여 성능,확장이 용이하다.
    단점으로는 네트워크 병목현상에 취약하며, 스케일업(하나의 NAS스토리지 장비자체의 성능업그레이드)에는 한계가있다. 도한 전송속도(대역폭)에 제한이있다. 

    SAN : 스토리지의 S이다. 동작방식은 NAS와 비슷하게 네트워크에 스토리지를 연결하여 사용하는것이지만, NAS와 다르게 '전용네트워크를 사용하고, SAN스위치라는 별도의 스위치를 사용하여 스토리지와 호스트를 연결한다.' 가상화 환경을 구축하기에 용이하다. NAS와 달리(NAS는 파일단위) SAN은 블록단위의 I/O(입출력)을 기본으로한다. (블록 스토리지 : 데이터를 블록이라는 일정한 크기의 조각으로나누어 정해진위치에 저장하고, 불러올때는 저장된 주소를 참고하여 데이터를 재구성하여 응답하는방식이다. 하둡이 데이터를 읽고,쓰고, 불러오는것을 생각하면됨)

### 멀티클라우드란?

기업이나 회사가 2개이상의 클라우드 제공업체의 클라우드 컴퓨팅기술을 이용하여 어플리케이션을 실행하는것이다. 일반적으로 두개이상의 클라우드, 프라이빗 클라우드(온프레미스)를 의미한다. **쿠버네티스가 오픈소스기반 멀티클라우드 솔루션이라고 할수있다.** 주로 멀티클라우드 솔루션은 다양한 클라우드 및 컴퓨팅 환경에서 애플리케이션을 마이그레이션,빌드,최적화하는 유연성과 이동성을 제공한다.

## 단어

-데이터 마이닝 : 결과를 예측하기위해 대용량 데이터세트에서 의미있는 패턴이나 통계적 규칙을 찾아내는것.

-데이터 파이프 라인 : 다양한 데이터 소스에서 원시데이터를 수집한다음 분석을위해 데이터 레이크나 데이터 웨어하우스같은 저장소로 흐름을 구성하는작업. 일반적으로 데이터 저장소에 저장되기전에 <u>전처리과정을 거치기때문에</u> ETL과 비슷할수도있지만 데이터 파이프라인이 조금더 광범위한 개념이다.
ETL은 추출 변환 로드, 즉 추출하고 변환하고 적재하는과정을 의미하지만 데이터 파이프라인은 데이터를 한 시스템에서 또다른시스템으로 옮겨가는작업을 뜻하기도하기에 좀 더 광범위하다.

-ETL: 추출 , 변환 ,로드 의 각 약자를 모은것이다. 다양한 데이터 소스 시스템의 데이터를 단일 통합 데이터 저장소(데이터 웨어하우스, 데이터 레이크)로 수집하고 처리하여 훨씬 쉽게 분석할수있도록 하는것이다.

-데이터 레이크 : 정형,반정형, 비정형 등 데이터를 비롯한 모든 가공되지않은 다양한 종류의 데이터를 한곳에 모아둔 중앙 레포지토리쯤으로 볼수있다.빅 데이터를 효율적으로 분석하고 사용하고자 다양한 영역의 Raw데이터를 한곳에 모아 관리하고자하는 목적이다.

-데이터 마켓 : 특정 팀 또는 사업단위의 요구를 충족시키는 데이터 웨어하우스. 일반적인 데이터 웨어하우스보다 규모가 작고 집중적이며 사용자 커뮤니티에 갖아 잘맞는 데이터 요약을 포함할수있다. 아무래도 데이터 웨어하우스보다는 작은개념이기에 데이터 웨어하우스 > 데이터 마켓 의 구조로도 표현할수있다. (즉 데이터웨어하우스에 데이터마켓이 포함되는것과같이.)
 
**-데이터웨어 하우스** : 사전적 의미로는, 기간시스템의 데이터 베이스에 축적된 데이터를 공통의 형식으로 변환해서 관리하는 데이터베이스를 말한다.
즉, <u>사용자 의사결정에 필요한 데이터가 들어있으면서 공통의 형식으로 관리되고있는 데이터베이스</u> 정도로 생각할수있겠다.

데이터 웨어 하우스의 목적으로는
    1.데이터를 기반한 의사결정이 가능
    2.여러 소스의 데이터를 통합해서 분석이가능
    3.과거 데이터분석이가능
    4.기존정보를 활용해서 더 나은정보 제공.

정도인데, 데이터 웨어하우스를 쓰는 이유를 알아야 데이터 웨어하우스를 좀 더 이해하기 쉬울거다.

그럼 데이터 웨어하우스는 왜 사용하는걸까? 일반 DB에 걍 쓰면안되나?싶은 생각이들겠는데, 일반 DB 즉 우리가 작은 토이프로젝트를 진행하면서 100GB언저리의 DB를 운영할때는 데이터 웨어하우스를 구축할 필요도없이 그냥 DB를 써도된다.

하지만, 빅데이터를 관리하거나,엄청나게 오랜기간동안 쌓여온 기간시스템(기간데이터)를 일반 DB에서 관리한다면 어떻게될까?

여기서 기간데이터란, 기간으로 이루어져있는 데이터를 의미한다. 예를들면 내가 운영하는것이 쇼핑몰이라고 가정한다면 DB에는 아래와같이 DB를 나눠서 관리할것이다.

    1.결제 관련 데이터(결제내역, 결제목록 등)
    2.재고 관리 시스템(현재 재고수량,부족한 재고수량 등등)
    3.주문관리 시스템(주문내역)
    4.회원관리 시스템(주소,유저ID,사용자 나이 및 이름 등등)

그럼 위와같은 4개의 데이터베이스에서 10개월 기간동안 회원들이 어떤품목을 얼마나 주문했는지 알아보고싶다면 회원관리 시스템 + 주문관리 시스템 DB에 쿼리를 작성해서 데이터 분석을 진행해야한다.

하지만, **운영 시스템에 SELECT,JOIN등 쿼리를 기간으로 작성하게된다면 시스템에 부하가 발생하게되어 앱이 동작하지않거나 분석을 진행하는동안은 마비가 발생할것이다.**

왜냐하면 시스템DB는 작은 규모의 데이터를 조회,삽입,삭제,수정을 빠르게하기위해 만들어진 시스템이라서 큰 규모의 데이터를 조회하게되면 부하가발생하게된다.


![DW예시](https://bomwo.cc/static/2eeda57fd16c202580f29dca7bf70d39/d26aa/example2.png)

<mark>그러한 부하를 발생시키지않으면서 운영DB를 추출하여 큰 규모의 데이터 조회 및 분석을위해 만들어진것이 데이터 웨어하우스이고, 데이터 웨어하우스를 사용하는 목적이다.</mark>

![DW아키텍쳐](https://bomwo.cc/static/ea188678e47519c7c158140455afd07b/d9199/snowflake.png)


-데이터 웨어하우스, 데이터 레이크 차이점 : DW,DL 둘 다 데이터를 저장하고 처리한다는 부분에서는 유사하지만, 서로 전담하고있는 분야가 다르다. 그러므로 보통 기업의 분석 에코시스템에는 DW,DL 둘다 포함하는것이 일반적이다. 그럼 DW와 DL의 궁극적 차이점은 무엇일까? <u>DW는 기본적으로 관계형이다.</u> 특정 목적을 염두에 두고 처리 및 변환된 데이터를 저장하여 분석 또는 운영 보고를하는데 사용할수있다. 데이터 웨어하우스는 보다 표준화된 형태의 BI 분석을 생성하거나 이미 정의된 비즈니스 사용 사례를  제공하는데 좀 더 적합하다.

반면 DL은 읽을때까지 스키마나 구조를 정의할 필요없이 반정형,비정형,정형의 데이터를 모두 저장하고 처리할수있다. 이것은 곧 DL이 유연하고 확장 가능한 특성으로인해 복잡한 형태의 데이터분석을 수행하는데 꼭 필요하다는 의미이다.


-리스트 : [a,b,c,d..]의 구조를 가지고있다. <u>요소를 삭제하거나 변경할수있다.</u> 는 점이 튜플과 가장 큰 차이점이다.한개의 리스트에 같은 타입의 데이터만 담을수있는게아니라 다른 타입의 데이터도 담을수있다.

-튜플 : (1,2,3,4..) 의 소괄호로 이루어진 구조를 가지고있다. 리스트와 동일하게 <u>서로 타입이 다른 데이터</u>를 담을수있다.
리스트와 가장 큰 차이점은 **요소를 삭제하거나 변경할수없다.**
append,remove등의 메소드로 삭제 변경 추가 등이 불가능하다. 정말로 삭제나 변경등을 하고싶다면 튜플+튜플 로 추가해주거나 인덱싱을통해 삭제하고자하는 요소와 남겨둘 요소를 떼어내야한다.

-dict : NoSql에서 가장많이 사용되는 자료포맷. 반환 타입은 dict이지만 set으로 구현된거라서 <u>중복이 불가능한 콜렉션 자료형</u>이다. {'key':'value'} 중괄호로 이루어져있으며, 키-값이 한쌍으로 이루어진 데이터 포맷이다. **중복이 불가능하다는것은 key의 값이 중복이불가능하다.** 밸류값에 리스트형식으로 여러값을 넣을수있다.

-set : **순서가없는 중복이불가능한 자료형**. 주로 리스트에서 순서를 보장받지않아도되면서 중복제거가 필요할때 많이쓰인다. list > set > list의 형식으로 다시 변환하면 순서가 엉망이되지만 중복은 제거가된다. 그외에노 합,교,차집합 등 수학적인 계산이 가능하다. <u>인덱싱이불가능</u>. add/update/remove 메소드를 활용하여 요소를 추가,삭제한다.

-정형 데이터 : 날짜, 시간 및 고객 ID같이 미리 정의된 특정 스키마를 가진 데이터베이스 테이블과 같이 형식이 정해진 항목으로 구조화되어있음.값과 숫자로 구성되어있다. 의미파악이 쉽고, 규칙적으로 입력되는값을 정형 데이터라고 볼수있다. (데이터베이스에 들어가있는 값이라고 다 정형은아니다)

-반정형 데이터 : 정형데이터에 비해 스키마가 유연하거나 생략되있을수있다. 데이터 구조에대한 최소한의 규칙만있으면된다. 그리드 형태의 셀 구조로된 스프레드시트는 셀 자체에 어떤 형태의 데이터도 담을수있는것처럼말이다. 비정형과 반정형이 섞인것이다. JSON 형식을 예로 들어본다면 json형식의 글 내용본문은 반정형이다(비+정 섞임), db에 저장된 글제목 > 비정형, db에 저장된 성별 > 정형

-비정형 데이터 : 어떠한 내부 구조가없는것. 일반 텍스트나 음성 이미지 영상 등 아무런 규칙도 구조도 없는 데이터들을 의미한다.

-선형

-비선형

-객체

-속성 : 테이블의 컬럼에 해당한다. 속성=어트리뷰트=열=차수=디그리

-튜플 : 테이블의 행에 해당한다. 속성의 모임으로볼수있다. 행=튜플=카디널리티. 파일구조의 레코드와 같은의미로 해석될수있다.

-스키마 : 관계형의 아이덴티티. 테이블에 자료를 담을 기본 구조 및 뼈대라고 설명할수있다.

-도메인 : 속성의 원자값.

-후보키 : 기본키가 될수있는 키의 집합. 유일성+최소성을 만족함으로써 아직 기본키가 선발되지않은 후보군이다. 모든 릴레이션은 반드시 하나이상의 후보키를 가져야한다.

-대체키 : 후보키에서 기본키가 되지못한 키들이 2개이상일때 이것을 대체키라고부름. 간단히말해서 후보키중에서 기본키가되지못한 키들.


-릴레이션 : db에서 정보를 구분하여 저장하는 기본단위이며 엔터티에 관한 데이터를 릴레이션에 담아관리한다. RDB에서의 릴레이션은 **테이블**을 의미하고, NoSql에선 **컬렉션**을 의미한다.

-엔터티 : 이것또한 테이블과같은 개념이다. 어떠한 정보를 관리하기위한 어떤것이라고 말할수있다. 또한 엔터티는 인스턴스가 두개 이상인 집합이여야한다.

-인스턴스 : 도메인정도로 이해할수있다. 예를들어 회사라는 엔터티에 인스턴스가 Lg cns한개라면 이것은 엔터티라고할수없다. 

![인스턴스와 엔터티](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FczQMMz%2FbtrP46bqbH2%2F7m6wkTxU6vKoMwU7lCs8MK%2Fimg.png)

즉, 엔터티 테이블 릴레이션 모두 완벽하게같은것을 의미하진않지만 거의 유사한 개념을가지고있어서 통칭해서 사용하기도한다.


**설계단계에서는 엔터티**

**구현단계에서는 테이블**

**개념단계에서 엔터티간의 연관관계를 릴레이션**

-엔터티,테이블,릴레이션 : 엔터티>테이블>릴레이션 의 관계를가지고있다고 보면된다.

-타임시리즈 데이터 : 시간의 흐름에따라 계속해서 생성되는 데이터.

-온프레미스 : 기업의 서버를 자체적으로 보유하고있는 서버에 직접 설치하고 운영하는 방식. 클라우드 이전에 가장 일반적으로 사용하던 시스템이고 직접인프라를 구축하는 방식을 의미한다.

-REST : 약자로 자원 이름을 구분하고 해당 자원의 상태와 자원을 주고받는것. 기본적으로 HTPP URL을 통해 명시하고 PUT,GET,POST,DELETE 를 통해 자원을 주고받는다.


-CRUD : 크리에이트,리드,업데이트,딜리트 의 약자. 가장 기본적인 데이터처리 기능을 묶어서 지칭하는말이다.

-REST API : REST의 원리를 따르는 API. HTTP(REST)요청을 통해 통신하여 CRUD작업을 수행할수있는 API.

-API : 데이터와 기능의 집합을 제공하여 프로그램간 상호작용을 도우며 서로정보를 교환하게하는기능.

-REST FUL : REST의 원리를 따르는 시스템. REST라는 아키텍쳐를 구현하는 웹 서비스를 나타내는 용어이기도함.

