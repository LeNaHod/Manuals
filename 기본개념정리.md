# 프로젝트를 진행하면서 사용한 기술스택들에대한 기본 개념정리

많지는않지만 프로젝트들을 진행하면서 여러 기술들을 사용하게되었다.
보통 프로젝트에 기술을 적용하면서 바로바로 기본개념들을 간단하게 정리해놨지만 기술들의 갯수가 많아지고 프로젝트에 적용시키면서 트러블슈팅들을 같이 작성해놓으니까 찾아보기가 힘들어지는 문제점이생겼다.

그래서 프로젝트에 이용했던 기술 스택들에대한 기본 개념들을 이곳에 정리해놓고 필요할때 찾아보는편이 낫겠다고 판단하여 작성.

- Celery
- Redis
- Airflow
- Django
- GCP
- Kafka
- Hadoop & hdfs
- Spark
- Elastic search
- logstash
- Kibana 
- SQL
- Nginx
- uWsgi
- Zookeeper
- Pandas
- Numpy
- Docker
- CloudFlare
## Celery와 사용이유

Celery는 많은 작업을 분산처리를 할 수있도록 해주는 Task queue이다. <u>Task는 비동기 처리를 도와주는 친구로 Celery는 비동기 작업 큐 라고 생각하면된다.</u>

<u>그럼 비동기 작업이 왜 필요한가?</u> 

이건 간단하게 생각하면 쉽다.
예를 들어 내가 스타벅스의 매장을 조회하기위하여 스타벅스 홈페이지에 접속하여 매장 조회를 눌렀다고 가정하자.

그런데 웹 페이지의 경우, 전국의 스타벅스 매장의 정보를 DB에서 가져오기때문에 이 가져오는 작업이 끝날때까지 나는 하염없이 웹 페이지의 응답을 기다려야한다.

그래서 그러한 무거운 연산 및 처리들을 Task라는 비동기 작업을 처리해주는 큐에 넘겨주고, 이용자는 다른작업을 할 수 있도록하는것이 원리이다.
그런고로 Celery는 클라이언트와 worker사이를 중재하는 메세지 브로커를 사용하여 통신하게되는데, worker들에게 task를 처리하도록 시키기위해 메세지 브로커로써 Redis나 Rabbit MQ를 사용하게된다.


그럼 queue는 뭘까? 이건 컨테이너벨트에 적재된 화물을 생각하면 쉽다.
예를들어, 택배사에서 컨테이너 벨트위에 배송되야할 택배들이 줄지어있다고치면 이 화물들이 처리해야할 작업이되는것이고 큐는 컨테이너벨트가되는것이다.

그러면 컨테이너벨트에 택배(화물)을 올려주는 작업을해주는 친구가 필요한데, 그 역할을하는게 시스템 브로커이다.

클라이언트에서 처리해야할 작업(task)를 생성하면 celery는 브로커를 통해 worker들에게 메세지를 전달하여 worker들이 해당 작업을 처리하게한다.

celery는 1분에 수백만건의 task를 처리할수있는 속도를 제공하기때문에 분산작업 처리를할때 유용하다.

보통 Airflow+celery+redis or rabbit mq를 많이 사용한다.

## Redis

<u>Airflow와 Redis</u>

redis를 airflow와 함께 사용할때는 보통 메세지 브로커로써 활용한다.
하지만 Redis의 태생 자체가 메세지 브로커가아니라 인 메모리 db로, <u>Key-value형식을가진 Nosql에 속하는 자료구조 서버이다</u>

우리가 흔히 사용하는 DB는 데이터를 물리 디스크에 직접써서 요청,쿼리가 발생할때마다 디스크에 접근하여 데이터를가져온다.
이러한 방법은 <u>서버에 장애가 발생하여도 데이터가 손실되지않는다.</u>

하지만 단점이있다.
사용자가 늘어가서 데이터베이스에 요청되는 쿼리가 커지고 많아진다면 디스크에 접근하는 횟수도 많아지기때문에 DB에 부하가발생하고 속도가 현저히 느려진다.

이때 캐시(메모리 기반) 서버를 도입하게되는데 이 Redis라는것이 인 메모리 DB이다.

캐시서버의 특징은 한번읽어온 데이터를 임의의 공간에 저장하여 다음에 읽을때 새로 읽어오는게 아니라 저장하고있던 정보를 빠르게 받아볼수있게 도와준다.

캐시서버가 한번 읽어온 데이터를 임의의 공간에 저장하고있기때문에, 당연히 매번 데이터베이스를 거치지않기때문에 DB의 부하를 줄이고 서비스 속도도 느려지지않는 장점이있다.

Airflow에서 redis를 같이쓰게되면 redis가 메세지 브로커로써 클라이언트가 생성한 Task가 지정된 큐에따라 redis서버안에 Key-Value타입으로 쌓이는것을 확인할수있다.

만약 내가 airflow task에 큐를 worker-1이라고 지정해놓으면 celery worker를 실행시킬때 워커가 모니터링할 큐를 worker-1이라고 지정해놓으면 해당 worker가 redis 큐 안의 task를 순차적으로 처리하게된다. 

redis 큐 안에 적재되는 task는 <u>task id</u>라는 고유한 task 아이디값이 있어서 아이디 값에따라 순차적으로 처리되는것을 확인할수있었다.

그렇다면 기본 Redis에 대해서 조금 더 알아보자.

Redis의 Key값의 자료형은 String형이지만 Value값의 자료형은 다양한 타입을 지원한다.

서버가 1개라면 굳이 Redis를 사용할필요는없겠지만(인 메모리 데이터베이스로써), 분산환경에서라면 원격 프로세스간의 데이터를 일치시키기가 Redis가 더욱 편리하다.

Redis의 단점은 무엇일까?

1.메모리 기반 DB이기때문에 서버에 장애가 발생했을시 데이터의 유실이있다.

2.메모리 기반 DB이기떄문에 메모리관리가중요하다.

3.싱글 스레드의 특성상, 처리하는데 시간이 오래걸리는 요청이나 명령은 비효율적이다.

### Redis VS Rabbit MQ

둘다 Airflow에서 메세지 브로커로 주로 활용된다.

두가지 다 Airflow와 사용하기 좋지만, 조금씩 특징이 다르다.

<u>Redis</u>

Key-Value를 이용해 Celery가 처리할 작업을 Celery에 보낸 후 캐시에서 해당 Key를 제거하는 방식으로 작동한다.

1.Redis는 데이터 검색을 위해 Database에 접근하기 전 메모리에서 Cache를 가져다 쓴다는 점에서 속도가 빠르다.

2.매우 빠른 서비스 및 메모리 내 기능을 제공하기 때문에 지속성이 중요하지 않고 약간의 손실을 견딜 수있는 짧은 보존 메시지에 적합하다.

3.큰 메시지를 처리 할 때는 대기 시간이 오래 걸린다.


<u> Rabbit MQ</u>

응용 프로그램(applications)에게 메시지를 주고 받을 수 있으며, 메시지가 수신될 때까지 안전하게 있을 수 있도록 하는 공용 플래폼(common platform)을 제공한다.

1.메시지를 다른 대기열로 보낼 수있는 라우팅 시스템을 갖추고 있다.

2.우선 순위가 높은 메시지를 먼저 사용하기 위해 작업자가 사용할 수있는 메시지의 우선 순위를 지원한다.

3.메시지 브로커로서 Redis와 비교할 때 훨씬 더 다양한 기능을 제공한다.
크고 복잡한 메시지에 적합하다.


<mark>나는 뉴스기사를 짧은간격으로 자주 수집해오는것을 목표</mark>로 하였기때문에, 약간의 데이터손실을 감당하고 빠른 속도가 장점인 Redis를 airflow에 적용시켰다.

## AirFlow 

Airflow는 오픈소스 워크플로 관리 플랫폼이다. 아파치 재단에서 만들었고, 파이썬으로 작성되어있으며 워크플로우를 작성할때 파이썬 스크립트를 통해 만들어진다.

Airflow를 접하다보면 <u>워크플로우</u>, <u>DAG</u>,<u>스케줄,스케줄링</u> 라는 단어를 많이 접하게된다. 이것들은 Airflow를 구성하는 아주 기본적인것들이며 Airflow를 사용하게된다면 좋든 싫든 친해져야할 친구들이다.


그럼 Airflow에대해서 상세하게 알아보자.

Airflow는 워크플로우 스케줄링(주기적으로 자동화시키길 원하는 스케줄의 관리)와 감시(모니터링)를하는 기능을 제공한다.

Airflow의 이름을 떠올려보면 이 도구가 뭐하는 도구인지 잘 알수있다.
바람개비인데 바람개비가 바람이불면 순차적으로 돌아가는것처럼 우리가 자동으로 작업되길 원하는 스케줄을 파이썬 스크립트파일을 통해 워크플로우( 의존성으로 연결된 작업들의 집합.)를 작성하면 Airflow가 이 워크플로우를 알아서 관리하고 실행시키고 모니터링한다.

Airflow가하는 역할을 예를들어본다면 이런거다.

우리는 알아서 식사시간이되면 식사를한다.
우리는 사람이기떄문에 알아서 때가되면 요리를하고 음식을만들고 음식을먹는 행동을한다.

**하지만 컴퓨터는 다르다.** 이 친구는 똑똑한것같으면서도 바보이기때문에 우리가 밥을먹으라고 명령을내려야 밥을먹는다.
하지만 이친구는 밥을먹으라고하면 정말 밥만먹는다. 먹을 밥이없으면 밥을만드는 그 전 단계를 처리하지않고 되려 오류를 발생시킨다.

*예를들면, 에러:먹을밥이없습니다. 이런식으로 말이다.*

그러면 우리(사용자)는 컴퓨터에게 하나하나 모든 작업을 스크립트파일로 명령을 내려줘야한다. 

요리 > 밥먹기 

이렇게보면 두개밖에없으니까 괜찮을것같지만 이런일을 매일매일, 식사뿐만아니라 우리가 하루를 보내듯 많은일을 시키려면 굉장히 번거로운 작업이될것이다.

그런것을 한번의 명령으로 컴퓨터가 알아서 동작하게하는것을 도와주는게, **Airflow**다.

단어를 조금 자세하게 살펴보자.

#### 개념 및 단어

- 워크플로우 : 의존성으로 연결된 작업들의 집합. 마트에가서 식자재를 사서와야 요리를할수있고, 요리를해야 점심식사를 할수있다. 이러한 작업들의 집합을 의미한다.

- DAG : 방향이 있는 순환되지않는 그래프(Directed Acyclic Graph)의 약자로 DAG라고 말한다. Task들의 집합이고, 작업집합의 그래프이기때문에 파이프라인으로 볼수있다. 점심식사를하기까지의 전체적인 흐름이라고 보면된다.
  
- Task : 아주작은 작업의 단위이다. 예를들면 마트에서 양파를사오기, 마트에서 계산을하기, 마트에서 장바구니를 구입하기 이런것들 하나하나가 각각의 Task가된다. 그리고 이 Task가 모여서 마트에서 장을보고 나오기 라는 하나의 DAG가 된다.


#### 에어플로우 구성요소

- Airflow_user: 나 (컴퓨터가밥먹길원하는사람)

- 웹서버 : 컴퓨터가 user가시킨 식재료를 제대로 사고있는지, 조리법대로 요리하고있는지 등을 감시하고 관리해서 내게 정보를 제공하는 화면. 내가 직접 컴퓨터에게 명령을 내려도 되지만, 웹 서버에게 명령을 내려도된다.

- 스케줄러 : 워크플로우 시간 관리 담당 비서같은녀석

- 메타스토어 : 여러 DAG들의 정보를 기록해놓은 파일함같은것. 해당 DAG가 왜 실패했는지, 어디서 문제가생겼는지 어떤 오류를 반환했는지를 기록한다.

- 익스큐터 : 작업을 배치하는 작업반장 역할을하는 친구이다. Airflow의 환경설정에서 바꿔줄수있다.

- 워커 : 작업반장에게서 작업을 할당받아서 일을해주는 친구. 

- 오퍼레이터 : 특정 작업을 수행할때 사용되는 기계같은것이다. 식기세척기를 떠올리면 적합하다. 이 오퍼레이터들을 이용하면 하나의 task가될수있다. (DAG:설거지, TASK:접시를닦기, 숟가락을 닦기, Operator:식기세척기) 이런식으로 이해하면 편하다.

<mark>예시</mark>

    with DAG :

        TASK_1:(
            식기세척기 오퍼레이터:
                숟가락 닦기
                ..
                .
        )

        TASK_2:(
            건조기 오퍼레이터:
                접시말리기
                ..
                .
        )

    TASK_1 >> TASK_2  # 이 친구는 DAG의 방향, 즉 파이프라인의 흐름을 지정하는것. 이것까지 완성해줘야 진정한 하나의 DAG가 완성된다.

DAG의 종류로는 

-generic_transfer : sql를 다룰때 주로 사용한다. airflow에서 수집, 가공되고있는 데이터를 지정한 db에 작성한 sql문을 실행하고 적재한다.

-Dummy : 아무작업도 하지않는 연산자로 다른 작업을 그룹화하는데 사용되는 오퍼레이터.

-＊Sensor : Task를 언제 실행시킬 트리거를 기다리는 특별한 오퍼레이터. (어떤 폴더에 데이터가 쌓이고있는지, hdfs에 내가 찾는 폴더나 파일이있는지 등을 감지하는 작업을하는 오퍼레이터)

-PythonOperator : 파이썬 코드, 함수등을 작업하게 도와주는 오퍼레이터.

-BashOperator : bash 명령어를 사용할수있도록 도와주는 오퍼레이터.

-sqlOperator :  sql 관련 작업들을 도와주는 오퍼레이터이다. 

-SimpleHttpOperator : HTTP요청을 보내고 응답 텍스트를 받는 작업을한다.

-HttpSensor : 응답(response)하는지 확인할 때 사용하는 센서 기계

간단하게 위와같은 오퍼레이터 및 센서들만 알아도 어느정도 작업은 다 처리할수있다. 


[Operator_정리](https://yhjin.tistory.com/26)

### Connections

ssh, sql 연동 정보등을 생성 및 등록하여 고유한 id로 연동정보를 불러서 사용한다.

웹서버에서 Admin->Connections 를 통해 등록할수있다.

자세한건 해당 페이지의 Airflow.md를 참조하자.

## 단어

-데이터 마이닝 : 결과를 예측하기위해 대용량 데이터세트에서 의미있는 패턴이나 통계적 규칙을 찾아내는것.

-데이터 파이프 라인

-ETL

-UDP

-TCP



